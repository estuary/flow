#!/bin/bash
#
# This script runs the examples catalog to completion using a temp-data-plane in --poll mode,
# and outputs selected materializations.

# -e causes the script to exit on encountering an error
# -m turns on job management, required for our use of `fg` below.
set -em


ROOTDIR="$(realpath $(git rev-parse --show-toplevel))"
cd "${ROOTDIR}"

function bail() {
    echo "$@" 1>&2
    exit 1
}

# The test to run, a folder name relative to `tests` directory
TEST=$1
# Root of the running test
TEST_ROOT="${ROOTDIR}/tests/${TEST}"
PGPASSWORD=${PGPASSWORD:-flow}

# Temporary test directory into which we'll build our test database,
# and stage temporary data plane files.
TESTDIR="$(mktemp -d -t flow-end-to-end-XXXXXXXXXX)"

echo "temporary test directory: $TESTDIR"

# Move sshd configs to the temp dir, which will be removed after execution.
cp -r "${ROOTDIR}/tests/sshforwarding/sshd-configs" "${TESTDIR}"

# Docker compose file for starting / stopping the testing SSH server and PSQL DB.
SSH_PSQL_DOCKER_COMPOSE="${TESTDIR}/sshd-configs/docker-compose.yaml"
function startTestInfra() {
  docker-compose --file ${SSH_PSQL_DOCKER_COMPOSE} up --detach
  # Allow postgres to be prepared.
  sleep 10
}
function stopTestInfra() {
  docker-compose --file ${SSH_PSQL_DOCKER_COMPOSE} down
}

function cleanupDataIfPassed() {
    if [[ -z "$TESTS_PASSED" ]]; then
        echo "Tests failed, retaining data dir: $TESTDIR"
    else
        echo "Tests passed, deleting data dir: $TESTDIR"
	# Need sudo and force deletion to delete some read-only temp files owned by root,
	# which are generated by the test infra of openssh server during testing.
        sudo rm -rf "$TESTDIR"
    fi
}

# Start local ssh server and postgres database.
startTestInfra

# `flowctl` commands which interact with the data plane look for *_ADDRESS
# variables, which are used by the temp-data-plane we're about to start.
export BROKER_ADDRESS=unix://localhost${TESTDIR}/gazette.sock
export CONSUMER_ADDRESS=unix://localhost${TESTDIR}/consumer.sock

# Start an empty local data plane within our TESTDIR as a background job.
# --poll so that connectors are polled rather than continuously tailed.
# --sigterm to verify we cleanly tear down the test catalog (otherwise it hangs).
# --tempdir to use our known TESTDIR rather than creating a new temporary directory.
# --unix-sockets to create UDS socket files in TESTDIR in well-known locations.
flowctl temp-data-plane \
    --poll \
    --sigterm \
    --tempdir ${TESTDIR} \
    --unix-sockets \
    --network=host \
    1>$TESTDIR/data-plane.stdout \
    2>$TESTDIR/data-plane.stderr \
    &
DATA_PLANE_PID=$!

tail -f $TESTDIR/data-plane.stdout &
tail -f $TESTDIR/data-plane.stderr &


# `flowctl temp-data-plane` always uses ./builds/ of --tempdir as its --flow.builds-root.
# See cmd-temp-data-plane.go.
export BUILDS_ROOT=${TESTDIR}/builds

# Arrange to stop the data plane on exit and remove the temporary directory.
trap "kill -s SIGKILL ${DATA_PLANE_PID} && stopTestInfra && cleanupDataIfPassed && killall tail" EXIT
# do not clean up temporary directory on SIGINT and SIGTERM
trap "kill -s SIGKILL ${DATA_PLANE_PID} && stopTestInfra && killall tail" SIGINT SIGTERM

BUILD_ID=run-end-to-end-${TEST}

touch $TESTDIR/build.stdout
touch $TESTDIR/build.stderr
tail -f $TESTDIR/build.stdout &
tail -f $TESTDIR/build.stderr &
# Build the catalog. Arrange for it to be removed on exit.
flowctl api build \
    --directory ${TESTDIR}/catalog-build \
    --network=host \
    --build-id ${BUILD_ID} \
    --source ${TEST_ROOT}/flow.yaml \
    --ts-package \
    1>>$TESTDIR/build.stdout \
    2>>$TESTDIR/build.stderr \
    || bail "Catalog build failed."
# Move the built database to the data plane's builds root.
mv ${TESTDIR}/catalog-build/${BUILD_ID} ${BUILDS_ROOT}/

touch $TESTDIR/activate.stdout
touch $TESTDIR/activate.stderr
tail -f $TESTDIR/activate.stdout &
tail -f $TESTDIR/activate.stderr &
# Activate the catalog.
flowctl api activate --network=host --log.level=debug --build-id ${BUILD_ID} --all 1>>$TESTDIR/activate.stdout 2>>$TESTDIR/activate.stderr || bail "Activate failed."

# allow writing tests for failure cases
set +e
# Wait for polling pass to finish.
touch $TESTDIR/await.stdout
touch $TESTDIR/await.stderr
tail -f $TESTDIR/await.stdout &
tail -f $TESTDIR/await.stderr &
flowctl api await --build-id ${BUILD_ID} 1>>$TESTDIR/await.stdout 2>>$TESTDIR/await.stderr
await_status_code=$!
set -e

echo "running checks against stdout and stderr files"
if [ -f $TEST_ROOT/data-plane.stdout ]; then
    cat $TESTDIR/data-plane.stdout | grep -f $TEST_ROOT/data-plane.stdout || bail "$TEST_ROOT/data-plane.stdout not found in $TESTDIR/data-plane.stdout"
fi
if [ -f $TEST_ROOT/data-plane.stderr ]; then
    cat $TESTDIR/data-plane.stderr | grep -f $TEST_ROOT/data-plane.stderr || bail "$TEST_ROOT/data-plane.stderr not found in $TESTDIR/data-plane.stderr"
fi
if [ -f $TEST_ROOT/build.stdout ]; then
    cat $TESTDIR/build.stdout | grep -f $TEST_ROOT/build.stdout || bail "$TEST_ROOT/build.stdout not found in $TESTDIR/build.stdout"
fi
if [ -f $TEST_ROOT/build.stderr ]; then
    cat $TESTDIR/build.stderr | grep -f $TEST_ROOT/build.stderr || bail "$TEST_ROOT/build.stderr not found in $TESTDIR/build.stderr"
fi
if [ -f $TEST_ROOT/activate.stdout ]; then
    cat $TESTDIR/activate.stdout | grep -f $TEST_ROOT/activate.stdout || bail "$TEST_ROOT/activate.stdout not found in $TESTDIR/activate.stdout"
fi
if [ -f $TEST_ROOT/activate.stderr ]; then
    cat $TESTDIR/activate.stderr | grep -f $TEST_ROOT/activate.stderr || bail "$TEST_ROOT/activate.stderr not found in $TESTDIR/activate.stderr"
fi
if [ -f $TEST_ROOT/await.stdout ]; then
    cat $TESTDIR/await.stdout | grep -f $TEST_ROOT/await.stdout || bail "$TEST_ROOT/await.stdout not found in $TESTDIR/await.stdout"
fi
if [ -f $TEST_ROOT/await.stderr ]; then
    cat $TESTDIR/await.stderr | grep -f $TEST_ROOT/await.stderr || bail "$TEST_ROOT/await.stderr not found in $TESTDIR/await.stderr"
fi

if [ $await_status_code -ne 0 ]; then
    echo "flowctl api await failed. will sleep for 5s to allow the materialization to finish."
    sleep 5
fi

function ssh_psql_exec() {
    docker-compose --file ${SSH_PSQL_DOCKER_COMPOSE} exec -T -e PGPASSWORD=flow postgres psql -w -U flow -d flow "$@"
}

echo "running checks against ${TEST_ROOT}/*.tunnel.rows"
shopt -s nullglob
# Data saved in tunneled postgres
for table_expected in ${TEST_ROOT}/*.tunnel.rows; do
    table_id=$(basename $table_expected .tunnel.rows)
    actual=${TESTDIR}/${table_id}.rows

    columns=$(head -n 1 $table_expected | sed 's/,/","/g')
    first_column=$(echo $columns | sed 's/",.*//')

    ssh_psql_exec -c "SELECT \"$columns\" FROM $table_id ORDER BY \"$first_column\";" --csv -P pager=off >> $actual
    diff --suppress-common-lines $actual $table_expected || bail "Test failed"
done

echo "running checks against ${TEST_ROOT}/*.local.rows"
# Data saved in local postgres
for table_expected in ${TEST_ROOT}/*.local.rows; do
    table_id=$(basename $table_expected .local.rows)
    actual=${TESTDIR}/${table_id}.rows

    columns=$(head -n 1 $table_expected | sed 's/,/","/g')
    first_column=$(echo $columns | sed 's/",.*//')

    psql -h localhost -w -U flow -d flow -c "SELECT \"$columns\" FROM $table_id ORDER BY \"$first_column\";" --csv -P pager=off >> $actual
    diff --suppress-common-lines $actual $table_expected || bail "Test failed"
done

echo "running checks against ${TEST_ROOT}/logs"
# Logs from connector. In this case we don't do a full diff between all lines, we just check
# that the expected logs exist among all the logs from the connector.
for table_expected in ${TEST_ROOT}/logs; do
    table_id="flow_logs"
    actual=${TESTDIR}/${table_id}

    columns=$(head -n 1 $table_expected | sed 's/,/","/g')
    # we don't want to grep the column names, so we create a headless version of the expected file
    headless_expected="$TESTDIR/$table_id.headless"
    tail +2 $table_expected > $headless_expected
    psql -h localhost -w -U flow -d flow -c "SELECT \"$columns\" FROM $table_id;" --csv -P pager=off >> $actual
    # content of $table_expected must be found in $actual
    cat $actual | grep -f $headless_expected || bail "$headless_expected not found in $actual"
done

echo "running flowctl api delete"
## Clean up the activated catalog.
flowctl api delete --network=host --build-id ${BUILD_ID} --all || bail "Delete failed."

# Setting this to true will cause TESTDIR to be cleaned up on exit
TESTS_PASSED=true
