begin;

create table public.connector_status (
    catalog_name public.catalog_name not null primary key,
    flow_document json not null
);
alter table public.connector_status owner to stats_loader;

comment on table public.connector_status is
'Holds the most recent status of the connector for each task, which is materialized
by the ops catalog.';
comment on column public.connector_status.catalog_name is
'The name of the task that the connector status is for. Tasks having multiple
shards will have a single connector status row, with the status itself being a
reduction of the statuses from all shards';
comment on column public.connector_status.flow_document is
'The contents of the `flow_document` column are serialized instances of the
`ConnectorStatus` struct defined in `crates/models/src/status/connector.rs`.';


create table public.shard_failures (
    catalog_name public.catalog_name not null,
    build public.flowid not null,
    ts timestamptz not null,
    flow_document json not null
);
alter table public.shard_failures owner to stats_loader;
-- Index to support controllers deleting old shard failures by name and build.
create index on public.shard_failures (catalog_name, build);
-- Index to support the cleanup cron job, and maybe also controllers deleting
-- shard failures by time.
create index on public.shard_failures (ts);

comment on table public.shard_failures is
'Records of task shard failures, which are materialized by the ops catalog using delta updates.
This table is effectively append-only. An insert into this table will trigger a run of the
corresponding live spec controller, which will respond to the failure and cleanup unneeded rows.';
comment on column public.shard_failures.catalog_name is
'The name of the task that the shard failure is for.';
comment on column public.shard_failures.build is
'The id of the build that the shard was running when it failed.';
comment on column public.shard_failures.ts is
'The timestamp of when the failure event was generated by the Flow runtime';
comment on column public.shard_failures.flow_document is
'The contents of the `flow_document` column are serialized instances of the
`ShardFailure` struct defined in `crates/models/src/status/activation.rs`.';


create function internal.on_shard_failure() returns trigger
LANGUAGE plpgsql SECURITY DEFINER
AS $$
declare
    controller_task_id public.flowid;
begin

    select ls.controller_task_id into controller_task_id
    from live_specs ls
    where ls.catalog_name = new.catalog_name;

    -- It is possible for shard failures to be observed after the task has been deleted.
    -- In that case, we just ignore the failure.
    if controller_task_id is not null then
        perform internal.send_to_task(
            controller_task_id,
            '00:00:00:00:00:00:00:00'::flowid,
            '{"type":"shard_failed"}'
            );
    end if;
return null;
end;
$$;

create function internal.delete_old_shard_failures() returns integer
LANGUAGE sql SECURITY DEFINER
as $$
    with deleted as (
        delete from public.shard_failures
        where ts < (now() - '48h'::interval)
        returning ts
    )
    select count(*) from deleted;
$$;

-- Run every weekday at 5pm. Controllers are supposed to clean up these failures
-- after at most 25 hours. But controllers cannot do so for failures that are
-- materialized after the live spec (along with the controller) has been
-- deleted, or if the controller itself is failing. So this is a catch-all to
-- clean up any shard failures don't get deleted by the normal process. Failures are
-- deleted after 48 hours, to give us time to investigate any potential issues that
-- may have prevented their deletion.
select cron.schedule('delete_old_shard_failures', '0 17 * * 1-5', 'internal.delete_old_shard_failures');

create trigger on_shard_failure_insert after insert on public.shard_failures
for each row
execute function internal.on_shard_failure();


alter table public.data_planes add column ops_l1_events_name public.catalog_name;
alter table public.data_planes add column ops_l2_events_transform text;

comment on column public.data_planes.ops_l1_events_name is
'The name of the L1 events derivation in the ops catalog';
comment on column public.data_planes.ops_l2_events_transform is
'The name of the events transform in the L2 events rollup of the ops catalog';

-- Populate these new columns. Note that the legacy data plane needs some
-- special handling because it doesn't follow the normal naming convention.
-- The substr call is to strip off the 'ops/dp/' prefix.
update public.data_planes
set
    ops_l1_events_name = case when data_plane_name = 'ops/dp/public/gcp-us-central1-c1'
        then 'ops/rollups/L1/public/gcp-us-central1-c1/events'
        else concat('ops/rollups/L1/', substr(data_plane_name, 8), '/events')
        end,
    ops_l2_events_transform = concat('from.', data_plane_fqdn, '.events')
where
    ops_l1_events_name is null and ops_l2_events_transform is null;

alter table public.data_planes alter column ops_l1_events_name set not null;
alter table public.data_planes alter column ops_l2_events_transform set not null;

commit;
