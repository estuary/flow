"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[3953],{22808:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"transformations/derivation-tutorial-python","title":"How to Transform Data Using Python","description":"This guide will teach you how to write and publish a simple Python derivation using async functions and Pydantic models.","source":"@site/docs/transformations/derivation-tutorial-python.md","sourceDirName":"transformations","slug":"/guides/transform_data_using_python/","permalink":"/guides/transform_data_using_python/","draft":false,"unlisted":false,"editUrl":"https://github.com/estuary/flow/edit/master/site/docs/transformations/derivation-tutorial-python.md","tags":[],"version":"current","frontMatter":{"slug":"/guides/transform_data_using_python/"},"sidebar":"docsSidebar","previous":{"title":"dbt Cloud Integration","permalink":"/guides/dbt-integration/"},"next":{"title":"How to Transform Data Using SQL","permalink":"/guides/derivation_tutorial_sql/"}}');var o=t(74848),a=t(28453);const s={slug:"/guides/transform_data_using_python/"},r="How to Transform Data Using Python",d={},l=[{value:"Introduction<a></a>",id:"introduction",level:2},{value:"Setting up your development environment<a></a>",id:"setting-up-your-development-environment",level:2},{value:"Writing the derivation<a></a>",id:"writing-the-derivation",level:2},{value:"Generating types<a></a>",id:"generating-types",level:2},{value:"The transformation code<a></a>",id:"the-transformation-code",level:2},{value:"Adding dependencies (optional)<a></a>",id:"adding-dependencies-optional",level:2},{value:"Verify<a></a>",id:"verify",level:2},{value:"Wrapping up<a></a>",id:"wrapping-up",level:2},{value:"Next steps",id:"next-steps",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"how-to-transform-data-using-python",children:"How to Transform Data Using Python"})}),"\n",(0,o.jsx)(n.p,{children:"This guide will teach you how to write and publish a simple Python derivation using async functions and Pydantic models."}),"\n",(0,o.jsx)(n.admonition,{type:"tip",children:(0,o.jsxs)(n.p,{children:["Python derivations can only be deployed to ",(0,o.jsx)(n.a,{href:"/private-byoc",children:"private or BYOC data planes"}),"."]})}),"\n",(0,o.jsxs)(n.h2,{id:"introduction",children:["Introduction",(0,o.jsx)("a",{id:"introduction"})]}),"\n",(0,o.jsx)(n.p,{children:"This tutorial will show you how to implement a stateless transformation using Python. You'll learn how to transform raw Wikipedia events into enriched, analytics-ready edit events by extracting structured information and categorizing page types."}),"\n",(0,o.jsxs)(n.h2,{id:"setting-up-your-development-environment",children:["Setting up your development environment",(0,o.jsx)("a",{id:"setting-up-your-development-environment"})]}),"\n",(0,o.jsxs)(n.p,{children:["In order to implement transformations through ",(0,o.jsx)(n.a,{href:"https://docs.estuary.dev/concepts/#derivations",children:"derivations"}),", you'll need to set up your development environment. You'll need a text editor and ",(0,o.jsx)(n.a,{href:"https://docs.estuary.dev/concepts/flowctl/",children:"flowctl"}),", the CLI-tool for Flow installed on your machine. Check out the ",(0,o.jsx)(n.a,{href:"https://docs.estuary.dev/concepts/flowctl/#installation-and-setup",children:"docs page"})," on installation instructions."]}),"\n",(0,o.jsxs)(n.p,{children:["Before continuing, sign in to the Estuary Flow dashboard, make sure you enable access to the Wikipedia demo. Using ",(0,o.jsx)(n.code,{children:"flowctl"}),", quickly verify you are able to view the demo collections used in this guide."]}),"\n",(0,o.jsxs)(n.p,{children:["Execute the below command to display the documents in the ",(0,o.jsx)(n.code,{children:"demo/wikipedia/recentchange-sampled"})," collection:"]}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.p,{children:["This collection is a 3% sample of the enormous ",(0,o.jsx)(n.code,{children:"demo/wikipedia/recentchange"})," collection which contains millions of documents. Since the purpose of this tutorial is to demonstrate a proof of concept, we avoid publishing a derivation that processes hundreds of gigabytes of data."]})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"flowctl collections read --collection demo/wikipedia/recentchange-sampled --uncommitted\n"})}),"\n",(0,o.jsxs)(n.p,{children:["If you see a stream of JSON documents on your terminal, you're all good - feel free to cancel the process by pressing ",(0,o.jsx)(n.code,{children:"Ctrl+C"}),"."]}),"\n",(0,o.jsx)(n.p,{children:"Examine a sample JSON that lives in the demo collection, as this is the data you'll be using as the input for our derivation."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",children:'{\n  "$schema": "/mediawiki/recentchange/1.0.0",\n  "_meta": {\n    "file": "recentchange",\n    "offset": 12837,\n    "uuid": "f8f07d87-f5bf-11ee-8401-4fdf95f7b91a"\n  },\n  "bot": false,\n  "comment": "[[:File:Jeton. Ordinaire des guerres - btv1b10405460g (1 of 2).jpg]] added to category",\n  "id": 2468434138,\n  "meta": {\n    "domain": "commons.wikimedia.org",\n    "dt": "2024-04-08T15:52:13Z",\n    "id": "d9e8698f-4eac-4262-a451-b7ca247e401c",\n    "offset": 5008568732,\n    "partition": 0,\n    "request_id": "b5372124-63fa-45e1-b35e-86784f1692bc",\n    "stream": "mediawiki.recentchange",\n    "topic": "eqiad.mediawiki.recentchange",\n    "uri": "https://commons.wikimedia.org/wiki/Category:Jetons"\n  },\n  "namespace": 14,\n  "notify_url": "https://commons.wikimedia.org/w/index.php?diff=866807860&oldid=861559382&rcid=2468434138",\n  "parsedcomment": "<a href=\\"/wiki/File:Jeton._Ordinaire_des_guerres_-_btv1b10405460g_(1_of_2).jpg\\" title=\\"File:Jeton. Ordinaire des guerres - btv1b10405460g (1 of 2).jpg\\">File:Jeton. Ordinaire des guerres - btv1b10405460g (1 of 2).jpg</a> added to category",\n  "server_name": "commons.wikimedia.org",\n  "server_script_path": "/w",\n  "server_url": "https://commons.wikimedia.org",\n  "timestamp": 1712591533,\n  "title": "Category:Jetons",\n  "title_url": "https://commons.wikimedia.org/wiki/Category:Jetons",\n  "type": "categorize",\n  "user": "Denghi\xf9Comm",\n  "wiki": "commonswiki"\n}\n'})}),"\n",(0,o.jsx)(n.p,{children:"There's a bunch of fields available. For this tutorial, you'll transform these raw events into enriched edit events that are ready for analytics. You'll extract:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Language code"})," from the domain (",(0,o.jsx)(n.code,{children:'"en.wikipedia.org"'})," \u2192 ",(0,o.jsx)(n.code,{children:'"en"'}),", ",(0,o.jsx)(n.code,{children:'"pt.wikipedia.org"'})," \u2192 ",(0,o.jsx)(n.code,{children:'"pt"'}),")"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Page category"})," from the namespace field (0 = Article, 1 = Talk, 2 = User page, etc.)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Structured event data"})," combining relevant fields into a clean schema"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"The goal is to create an output collection that a data analyst would actually want to work with - clean, enriched events with meaningful properties instead of nested raw fields."}),"\n",(0,o.jsxs)(n.h2,{id:"writing-the-derivation",children:["Writing the derivation",(0,o.jsx)("a",{id:"writing-the-derivation"})]}),"\n",(0,o.jsxs)(n.p,{children:["Set up your folder structure so you can organize the resources required for the derivation. Create a working directory to follow along, and inside, create a ",(0,o.jsx)(n.code,{children:"flow.yaml"})," file."]}),"\n",(0,o.jsxs)(n.p,{children:["Inside your ",(0,o.jsx)(n.code,{children:"flow.yaml"})," file, add the following contents (replace ",(0,o.jsx)(n.code,{children:"AcmeCo"})," with your own username or organization prefix):"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:"---\ncollections:\n  AcmeCo/derivation-tutorial/wiki-edit-events:\n    schema: wiki-edit-events.schema.yaml\n    key:\n      - /edit_id\n    derive:\n      using:\n        python:\n          module: wiki-edit-events.flow.py\n      transforms:\n        - name: enrichEvents\n          source: demo/wikipedia/recentchange-sampled\n          shuffle: any\n"})}),"\n",(0,o.jsxs)(n.p,{children:["The Flow consists of just one collection, which is what you define here, called ",(0,o.jsx)(n.code,{children:"AcmeCo/derivation-tutorial/wiki-edit-events"}),"."]}),"\n",(0,o.jsx)(n.p,{children:"Let's go over this in a bit more detail."}),"\n",(0,o.jsxs)(n.p,{children:["First of all, the collection needs a schema. The schema of the incoming data is already attached to the ",(0,o.jsx)(n.code,{children:"source"})," collection we're using in this demo, you only have to define the schema of the documents the transformation will output."]}),"\n",(0,o.jsxs)(n.p,{children:["Create a new file ",(0,o.jsx)(n.code,{children:"wiki-edit-events.schema.yaml"})," alongside your ",(0,o.jsx)(n.code,{children:"flow.yaml"})," with the following contents:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:"type: object\nproperties:\n  edit_id:\n    type: integer\n    description: Unique identifier for this edit\n  wiki_language:\n    type: string\n    description: Language code extracted from domain (en, es, pt, etc.)\n  page_title:\n    type: string\n    description: Title of the page being edited\n  page_category:\n    type: string\n    description: Category of page (Article, Talk, User, etc.)\n  editor_name:\n    type: string\n    description: Username of the editor\n  is_bot:\n    type: boolean\n    description: Whether this edit was made by a bot\n  timestamp:\n    type: string\n    format: date-time\n    description: When the edit occurred\n  edit_url:\n    type: string\n    description: URL to view the edit\nrequired:\n  - edit_id\n  - wiki_language\n  - page_title\n  - page_category\n  - editor_name\n  - is_bot\n  - timestamp\n"})}),"\n",(0,o.jsxs)(n.p,{children:["This schema defines clean, analytics-ready fields. Instead of keeping nested raw data like ",(0,o.jsx)(n.code,{children:"meta.domain"}),", you'll extract the language code into ",(0,o.jsx)(n.code,{children:"wiki_language"}),'. Instead of cryptic namespace numbers, you\'ll map them to readable categories like "Article" or "Talk".']}),"\n",(0,o.jsx)(n.p,{children:"In the collection yaml definition, the next section defines the key of the documents."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:"key:\n  - /edit_id\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Every Flow collection must declare a key which is used to group its documents. Keys are specified as an array of JSON pointers to document locations. Since each Wikipedia edit has a unique ",(0,o.jsx)(n.code,{children:"id"})," field, you'll use the transformed ",(0,o.jsx)(n.code,{children:"edit_id"})," as the key. This ensures each edit event is uniquely identifiable in your collection."]}),"\n",(0,o.jsx)(n.p,{children:"The final section is where you specify that this collection is derived from another collection."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:"derive:\n  using:\n    python:\n      module: wiki-edit-events.flow.py\n  transforms:\n    - name: enrichEvents\n      source: demo/wikipedia/recentchange-sampled\n      shuffle: any\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Here you configure the name of the Python file that will contain the transformation code and give a name to the transformation: ",(0,o.jsx)(n.code,{children:"enrichEvents"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"source: demo/wikipedia/recentchange-sampled"})," property specifies the source collection, while ",(0,o.jsx)(n.code,{children:"shuffle"})," tells Flow how to colocate documents while processing, which in this case is set to ",(0,o.jsx)(n.code,{children:"any"}),", meaning source documents can be processed by any scaled-out instance of the derivation."]}),"\n",(0,o.jsxs)(n.p,{children:["Now that you have both ",(0,o.jsx)(n.code,{children:"flow.yaml"})," and ",(0,o.jsx)(n.code,{children:"wiki-edit-events.schema.yaml"})," created, you're ready to generate the Python scaffolding."]}),"\n",(0,o.jsxs)(n.h2,{id:"generating-types",children:["Generating types",(0,o.jsx)("a",{id:"generating-types"})]}),"\n",(0,o.jsxs)(n.p,{children:["The next step is to use ",(0,o.jsx)(n.code,{children:"flowctl"})," to generate Python type stubs you can use as an aid when writing the transformation code."]}),"\n",(0,o.jsx)(n.p,{children:"Execute the following command:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"flowctl generate --source flow.yaml\n"})}),"\n",(0,o.jsxs)(n.p,{children:["If everything went well, you'll see a bunch of new files that ",(0,o.jsx)(n.code,{children:"flowctl"})," generated for you in your working directory."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"\u279c tree\n.\n\u251c\u2500\u2500 flow.yaml\n\u251c\u2500\u2500 flow_generated\n\u2502   \u2514\u2500\u2500 python\n\u2502       \u2514\u2500\u2500 AcmeCo\n\u2502           \u2514\u2500\u2500 derivation_tutorial\n\u2502               \u2514\u2500\u2500 wiki_edit_events\n\u2502                   \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 pyrightconfig.json\n\u251c\u2500\u2500 wiki-edit-events.flow.py\n\u2514\u2500\u2500 wiki-edit-events.schema.yaml\n\n6 directories, 6 files\n"})}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.p,{children:["The tree output may show additional ",(0,o.jsx)(n.code,{children:"__init__.py"})," files in intermediate directories - this is expected Python package structure."]})}),"\n",(0,o.jsxs)(n.p,{children:["The folder ",(0,o.jsx)(n.code,{children:"flow_generated"})," along with the ",(0,o.jsx)(n.code,{children:"pyproject.toml"})," and ",(0,o.jsx)(n.code,{children:"pyrightconfig.json"})," files are things you won't have to modify during this tutorial. The ",(0,o.jsx)(n.code,{children:"wiki-edit-events.flow.py"})," file was generated as a skeleton that you'll implement in the next section. If you take a look at the file that ",(0,o.jsx)(n.code,{children:"flowctl"})," generated under ",(0,o.jsx)(n.code,{children:"flow_generated/python/AcmeCo/derivation_tutorial/wiki_edit_events/__init__.py"}),", you can see the types you are able to use in your transformations."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# Generated for published documents of derived collection AcmeCo/derivation-tutorial/wiki-edit-events\nclass Document(pydantic.BaseModel):\n    edit_id: int\n    wiki_language: str\n    page_title: str\n    page_category: str\n    editor_name: str\n    is_bot: bool\n    timestamp: str\n    edit_url: typing.Optional[str] = None\n"})}),"\n",(0,o.jsx)(n.p,{children:"Flow has automatically generated Pydantic models based on your collection schemas. These models give you full type safety and IDE autocomplete while writing your transformation code. Notice how these match the schema you defined - clean, structured fields for analytics."}),"\n",(0,o.jsx)(n.p,{children:"You'll also see types for reading from source collections:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# Generated for read documents of sourced collection demo/wikipedia/recentchange-sampled\nclass SourceEnrichEvents(pydantic.BaseModel):\n    class Meta(pydantic.BaseModel):\n        domain: str\n        dt: str\n        # ... other meta fields\n\n    id: int\n    meta: Meta\n    title: str\n    user: str\n    namespace: int\n    bot: bool\n    notify_url: typing.Optional[str] = None\n    # ... many other fields from the Wikipedia schema\n"})}),"\n",(0,o.jsx)(n.p,{children:"The source type includes all fields from the Wikipedia events. You'll use these in your transformation to extract and map data into your enriched format."}),"\n",(0,o.jsxs)(n.p,{children:["Now, the actual transformation code will live in the file ",(0,o.jsx)(n.code,{children:"wiki-edit-events.flow.py"}),". Take a look at the default contents that ",(0,o.jsx)(n.code,{children:"flowctl generate"})," created:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'"""Derivation implementation for AcmeCo/derivation-tutorial/wiki-edit-events."""\nfrom collections.abc import AsyncIterator\nfrom AcmeCo.derivation_tutorial.wiki_edit_events import IDerivation, Document, Request\n\n# Implementation for derivation AcmeCo/derivation-tutorial/wiki-edit-events.\nclass Derivation(IDerivation):\n    async def enrich_events(self, read: Request.ReadEnrichEvents) -> AsyncIterator[Document]:\n        raise NotImplementedError("enrich_events not implemented")\n        if False:\n            yield  # Mark as a generator.\n'})}),"\n",(0,o.jsxs)(n.p,{children:["Helpfully, ",(0,o.jsx)(n.code,{children:"flowctl"})," provides a skeleton function. Note that the transform name ",(0,o.jsx)(n.code,{children:"enrichEvents"})," has been converted to the snake_case method name ",(0,o.jsx)(n.code,{children:"enrich_events"})," following Python conventions."]}),"\n",(0,o.jsxs)(n.h2,{id:"the-transformation-code",children:["The transformation code",(0,o.jsx)("a",{id:"the-transformation-code"})]}),"\n",(0,o.jsx)(n.p,{children:"Update the function body to implement the enrichment logic:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'"""Derivation implementation for AcmeCo/derivation-tutorial/wiki-edit-events."""\nfrom collections.abc import AsyncIterator\nfrom AcmeCo.derivation_tutorial.wiki_edit_events import IDerivation, Document, Request\n\n\n# Mapping of Wikipedia namespace IDs to human-readable categories\nNAMESPACE_CATEGORIES = {\n    0: "Article",\n    1: "Talk",\n    2: "User",\n    3: "User Talk",\n    4: "Wikipedia",\n    5: "Wikipedia Talk",\n    6: "File",\n    14: "Category",\n    # ... and many more\n}\n\n\nclass Derivation(IDerivation):\n    async def enrich_events(self, read: Request.ReadEnrichEvents) -> AsyncIterator[Document]:\n        """Transform raw Wikipedia events into enriched, analytics-ready edit events."""\n\n        # Extract language code from domain (e.g., "en.wikipedia.org" -> "en")\n        domain = read.doc.meta.domain if read.doc.meta else ""\n        wiki_language = domain.split(\'.\')[0] if domain else "unknown"\n\n        # Map namespace number to readable category\n        page_category = NAMESPACE_CATEGORIES.get(read.doc.namespace, "Other")\n\n        # Build the enriched event\n        yield Document(\n            edit_id=read.doc.id,\n            wiki_language=wiki_language,\n            page_title=read.doc.title,\n            page_category=page_category,\n            editor_name=read.doc.user,\n            is_bot=read.doc.bot,\n            timestamp=read.doc.meta.dt if read.doc.meta else "",\n            edit_url=read.doc.notify_url,\n        )\n'})}),"\n",(0,o.jsx)(n.p,{children:"Let's break down what's happening here:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Async Iterator"}),": The method is defined as an async generator using ",(0,o.jsx)(n.code,{children:"async def"})," and ",(0,o.jsx)(n.code,{children:"yield"}),". This allows Flow to process documents efficiently in an asynchronous manner."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Type Safety"}),": The ",(0,o.jsx)(n.code,{children:"read"})," parameter is typed as ",(0,o.jsx)(n.code,{children:"Request.ReadEnrichEvents"}),", which is a Pydantic model. This gives you autocomplete in your IDE and catches type errors early."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Data Extraction"}),": You extract the language code from the domain using Python's string manipulation. For example, ",(0,o.jsx)(n.code,{children:'"en.wikipedia.org"'})," becomes ",(0,o.jsx)(n.code,{children:'"en"'}),"."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Mapping Logic"}),": The ",(0,o.jsx)(n.code,{children:"NAMESPACE_CATEGORIES"}),' dictionary maps Wikipedia\'s numeric namespace IDs to human-readable categories. Namespace 0 is "Article", 1 is "Talk", 2 is "User", etc.']}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Document Construction"}),": You construct a new ",(0,o.jsx)(n.code,{children:"Document"})," instance with clean, transformed fields. This is what makes the output analytics-ready - instead of nested raw fields, you have structured, meaningful properties."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Yielding"}),": You use ",(0,o.jsx)(n.code,{children:"yield"})," to emit the transformed document. Python derivations use async generators to efficiently process streams of documents."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Every incoming Wikipedia event gets transformed into a clean, enriched edit event with extracted metadata and human-readable categorization."}),"\n",(0,o.jsxs)(n.h2,{id:"adding-dependencies-optional",children:["Adding dependencies (optional)",(0,o.jsx)("a",{id:"adding-dependencies"})]}),"\n",(0,o.jsxs)(n.p,{children:["If your derivation needs additional Python packages, you can specify them in the ",(0,o.jsx)(n.code,{children:"flow.yaml"})," configuration:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:'derive:\n  using:\n    python:\n      module: wiki-edit-events.flow.py\n      dependencies:\n        requests: ">=2.31.0"\n        pandas: ">=2.0"\n  transforms:\n    - name: enrichEvents\n      source: demo/wikipedia/recentchange-sampled\n      shuffle: any\n'})}),"\n",(0,o.jsxs)(n.p,{children:["Flow uses ",(0,o.jsx)(n.a,{href:"https://docs.astral.sh/uv/",children:"uv"}),", a fast Python package manager, to automatically install and manage your dependencies. The ",(0,o.jsx)(n.code,{children:"pydantic"})," and ",(0,o.jsx)(n.code,{children:"pyright"})," packages are always included automatically."]}),"\n",(0,o.jsxs)(n.h2,{id:"verify",children:["Verify",(0,o.jsx)("a",{id:"verify"})]}),"\n",(0,o.jsxs)(n.p,{children:["You can use ",(0,o.jsx)(n.code,{children:"flowctl"})," to quickly verify your derivation before publishing it. Use the ",(0,o.jsx)(n.code,{children:"preview"})," command to see the enriched events in action:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:'\u279c flowctl preview --source flow.yaml\n\n{"edit_id":1951027655,"wiki_language":"en","page_title":"User:Jengod/sandbox","page_category":"User","editor_name":"Jengod","is_bot":false,"timestamp":"2025-10-02T00:00:00.084Z","edit_url":"https://en.wikipedia.org/w/index.php?diff=1314539935&oldid=1314539378"}\n{"edit_id":1951027661,"wiki_language":"en","page_title":"Talk:Cassini\'s Division","page_category":"Talk","editor_name":"Wizardman","is_bot":false,"timestamp":"2025-10-02T00:00:02.594Z","edit_url":"https://en.wikipedia.org/w/index.php?diff=1314539937&oldid=1312331396"}\n{"edit_id":138916568,"wiki_language":"pt","page_title":"Cowboy Carter Tour","page_category":"Article","editor_name":"Haineee","is_bot":false,"timestamp":"2025-10-02T00:00:02.879Z","edit_url":"https://pt.wikipedia.org/w/index.php?diff=70956670&oldid=70937508"}\n{"edit_id":1951027714,"wiki_language":"en","page_title":"Talk:2000 Hong Kong-Macau Interport","page_category":"Talk","editor_name":"AnomieBOT","is_bot":true,"timestamp":"2025-10-02T00:00:09.535Z","edit_url":"https://en.wikipedia.org/w/index.php?diff=1314539964&oldid=781663774"}\n^C\n'})}),"\n",(0,o.jsxs)(n.p,{children:["Perfect! The output shows clean, enriched events with extracted language codes (",(0,o.jsx)(n.code,{children:'"en"'}),", ",(0,o.jsx)(n.code,{children:'"pt"'}),"), readable page categories (",(0,o.jsx)(n.code,{children:'"User"'}),", ",(0,o.jsx)(n.code,{children:'"Talk"'}),", ",(0,o.jsx)(n.code,{children:'"Article"'}),"), and all the structured fields you defined. This is exactly what you'd want for analytics or monitoring dashboards."]}),"\n",(0,o.jsx)(n.p,{children:"You can now publish your derivation to make it run continuously:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"flowctl catalog publish --source flow.yaml\n"})}),"\n",(0,o.jsx)(n.admonition,{type:"warning",children:(0,o.jsx)(n.p,{children:"Publishing will activate your derivation to continuously process the Wikipedia sample stream and store the results. This will consume storage and compute resources. Make sure to delete the collection after completing the tutorial to avoid unnecessary costs."})}),"\n",(0,o.jsx)(n.p,{children:"After successfully publishing your derivation, head over to the Collections page on the Web UI and you will be able to see your derivation in action!"}),"\n",(0,o.jsxs)(n.h2,{id:"wrapping-up",children:["Wrapping up",(0,o.jsx)("a",{id:"wrapping-up"})]}),"\n",(0,o.jsx)(n.p,{children:"In this guide you learned how to write your first stateless Python derivation to transform raw events into enriched, analytics-ready data. You've seen how:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Flow automatically generates Pydantic models from your JSON schemas"}),"\n",(0,o.jsx)(n.li,{children:"Python derivations use async generators to efficiently process documents"}),"\n",(0,o.jsx)(n.li,{children:"You can extract and transform data using simple Python logic"}),"\n",(0,o.jsx)(n.li,{children:"Type safety helps catch errors during development"}),"\n",(0,o.jsx)(n.li,{children:"The Python connector integrates seamlessly with the broader Python ecosystem"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"The enriched events you created demonstrate a real-world pattern: taking raw operational data and transforming it into clean, structured data ready for analytics, dashboards, or machine learning pipelines."}),"\n",(0,o.jsx)(n.h3,{id:"next-steps",children:"Next steps"}),"\n",(0,o.jsx)(n.p,{children:"This tutorial covered the basics of stateless Python derivations. For more advanced patterns, check out:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Stateful derivations"}),": Learn how to maintain persistent state across documents and task restarts in the ",(0,o.jsx)(n.a,{href:"https://github.com/estuary/flow/blob/master/examples/derive-patterns/stateful.flow.py",children:"stateful example"})]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Async pipelining"}),": Process documents with bounded concurrency for API calls and I/O operations in the ",(0,o.jsx)(n.a,{href:"https://github.com/estuary/flow/blob/master/examples/derive-patterns/pipeline.flow.py",children:"pipeline example"})]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"All derivation patterns"}),": Explore the complete set of examples in the ",(0,o.jsx)(n.a,{href:"https://github.com/estuary/flow/tree/master/examples/derive-patterns",children:"derive-patterns directory"})]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>r});var i=t(96540);const o={},a=i.createContext(o);function s(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);