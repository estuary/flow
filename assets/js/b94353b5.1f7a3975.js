"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[848],{28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>o});var i=t(96540);const a={},r=i.createContext(a);function s(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),i.createElement(r.Provider,{value:n},e.children)}},63995:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"reference/Connectors/materialization-connectors/Dekaf/materialize","title":"Materialize","description":"This connector materializes Flow collections as Kafka-compatible messages that a Materialize Kafka consumer can read. Materialize is an operational data warehouse for real-time analytics that uses standard SQL","source":"@site/docs/reference/Connectors/materialization-connectors/Dekaf/materialize.md","sourceDirName":"reference/Connectors/materialization-connectors/Dekaf","slug":"/reference/Connectors/materialization-connectors/Dekaf/materialize","permalink":"/reference/Connectors/materialization-connectors/Dekaf/materialize","draft":false,"unlisted":false,"editUrl":"https://github.com/estuary/flow/edit/master/site/docs/reference/Connectors/materialization-connectors/Dekaf/materialize.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Imply Polaris","permalink":"/reference/Connectors/materialization-connectors/Dekaf/imply-polaris"},"next":{"title":"RisingWave","permalink":"/reference/Connectors/materialization-connectors/Dekaf/risingwave"}}');var a=t(74848),r=t(28453);const s={},o="Materialize",c={},l=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Variants",id:"variants",level:2},{value:"Setup",id:"setup",level:2},{value:"Connecting Estuary Flow to Materialize",id:"connecting-estuary-flow-to-materialize",level:2},{value:"Creating Real-Time Views",id:"creating-real-time-views",level:3},{value:"Configuration",id:"configuration",level:2},{value:"Properties",id:"properties",level:3},{value:"Endpoint",id:"endpoint",level:4},{value:"Bindings",id:"bindings",level:4},{value:"Sample",id:"sample",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"materialize",children:"Materialize"})}),"\n",(0,a.jsxs)(n.p,{children:["This connector materializes Flow collections as Kafka-compatible messages that a Materialize Kafka consumer can read. ",(0,a.jsx)(n.a,{href:"https://materialize.com/",children:"Materialize"})," is an operational data warehouse for real-time analytics that uses standard SQL\nfor defining transformations and queries."]}),"\n",(0,a.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsx)(n.p,{children:"To use this connector, you'll need:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"At least one Flow collection"}),"\n",(0,a.jsx)(n.li,{children:"A Materialize account"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"variants",children:"Variants"}),"\n",(0,a.jsxs)(n.p,{children:["This connector is a variant of the default Dekaf connector. For other integration options, see the main ",(0,a.jsx)(n.a,{href:"/reference/Connectors/materialization-connectors/Dekaf/",children:"Dekaf"})," page."]}),"\n",(0,a.jsx)(n.h2,{id:"setup",children:"Setup"}),"\n",(0,a.jsx)(n.p,{children:"Provide an auth token when setting up the Dekaf connector. This can be a password of your choosing and will be used to authenticate consumers to your Kafka topics."}),"\n",(0,a.jsxs)(n.p,{children:["Once the connector is created, note the full materialization name, such as ",(0,a.jsx)(n.code,{children:"YOUR-ORG/YOUR-PREFIX/YOUR-MATERIALIZATION"}),". You will use this as the username."]}),"\n",(0,a.jsx)(n.h2,{id:"connecting-estuary-flow-to-materialize",children:"Connecting Estuary Flow to Materialize"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"In your Materialize dashboard, use the SQL shell to create a new secret and connection using the Kafka source\nconnector. Use the following SQL commands to configure the connection to Estuary Flow:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE\nSECRET estuary_token AS\n  'your_materialization_auth_token_here';\n\nCREATE\nCONNECTION estuary_connection TO KAFKA (\n    BROKER 'dekaf.estuary-data.com',\n    SECURITY PROTOCOL = 'SASL_SSL',\n    SASL MECHANISMS = 'PLAIN',\n    SASL USERNAME = 'YOUR/MATERIALIZATION/NAME',\n    SASL PASSWORD = SECRET estuary_token\n);\n\nCREATE\nCONNECTION csr_estuary_connection TO CONFLUENT SCHEMA REGISTRY (\n    URL 'https://dekaf.estuary-data.com',\n    USERNAME = 'YOUR/MATERIALIZATION/NAME',\n    PASSWORD = SECRET estuary_token\n);\n"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Create a source in Materialize"})," to read from the Kafka topic. Use the following SQL command,\nreplacing ",(0,a.jsx)(n.code,{children:"<name-of-your-flow-collection>"})," with the name of a collection you added to your Estuary Flow materialization:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE SOURCE materialize_source\nFROM KAFKA CONNECTION estuary_connection (TOPIC '<name-of-your-flow-collection>')\nFORMAT AVRO USING CONFLUENT SCHEMA REGISTRY CONNECTION csr_estuary_connection\nENVELOPE UPSERT;\n"})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"creating-real-time-views",children:"Creating Real-Time Views"}),"\n",(0,a.jsx)(n.p,{children:"To begin analyzing the data, create a real-time view using SQL in Materialize. Here is an example query to create a\nmaterialized view that tracks data changes:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"CREATE MATERIALIZED VIEW my_view AS\nSELECT *\nFROM materialize_source;\n"})}),"\n",(0,a.jsxs)(n.p,{children:["For more detailed information on creating materialized views and other advanced configurations, refer to\nthe ",(0,a.jsx)(n.a,{href:"https://materialize.com/docs/",children:"Materialize documentation"}),"."]}),"\n",(0,a.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,a.jsx)(n.p,{children:"To use this connector, begin with data in one or more Flow collections.\nUse the below properties to configure a Dekaf materialization, which will direct one or more of your Flow collections to your desired topics."}),"\n",(0,a.jsx)(n.h3,{id:"properties",children:"Properties"}),"\n",(0,a.jsx)(n.h4,{id:"endpoint",children:"Endpoint"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Property"}),(0,a.jsx)(n.th,{children:"Title"}),(0,a.jsx)(n.th,{children:"Description"}),(0,a.jsx)(n.th,{children:"Type"}),(0,a.jsx)(n.th,{children:"Required/Default"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"/token"})}),(0,a.jsx)(n.td,{children:"Auth Token"}),(0,a.jsx)(n.td,{children:"The password that Kafka consumers can use to authenticate to this task."}),(0,a.jsx)(n.td,{children:"string"}),(0,a.jsx)(n.td,{children:"Required"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"/strict_topic_names"})}),(0,a.jsx)(n.td,{children:"Strict Topic Names"}),(0,a.jsx)(n.td,{children:"Whether or not to expose topic names in a strictly Kafka-compliant format."}),(0,a.jsx)(n.td,{children:"boolean"}),(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"false"})})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"/deletions"})}),(0,a.jsx)(n.td,{children:"Deletion Mode"}),(0,a.jsxs)(n.td,{children:["Can choose between ",(0,a.jsx)(n.code,{children:"kafka"})," or ",(0,a.jsx)(n.code,{children:"cdc"})," deletion modes."]}),(0,a.jsx)(n.td,{children:"string"}),(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"kafka"})})]})]})]}),"\n",(0,a.jsx)(n.h4,{id:"bindings",children:"Bindings"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Property"}),(0,a.jsx)(n.th,{children:"Title"}),(0,a.jsx)(n.th,{children:"Description"}),(0,a.jsx)(n.th,{children:"Type"}),(0,a.jsx)(n.th,{children:"Required/Default"})]})}),(0,a.jsx)(n.tbody,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"/topic_name"})}),(0,a.jsx)(n.td,{children:"Topic Name"}),(0,a.jsx)(n.td,{children:"Kafka topic name that Dekaf will publish under."}),(0,a.jsx)(n.td,{children:"string"}),(0,a.jsx)(n.td,{children:"Required"})]})})]}),"\n",(0,a.jsx)(n.h3,{id:"sample",children:"Sample"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"materializations:\n  ${PREFIX}/${mat_name}:\n    endpoint:\n      dekaf:\n        config:\n          token: <auth-token>\n          strict_topic_names: false\n          deletions: kafka\n        variant: materialize\n    bindings:\n      - resource:\n          topic_name: ${COLLECTION_NAME}\n        source: ${PREFIX}/${COLLECTION_NAME}\n"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);