"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[5216],{8901:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"guides/dbt-integration","title":"dbt Cloud Integration","description":"Estuary Flow offers an integration with dbt Cloud, enabling users to trigger dbt jobs automatically when new data","source":"@site/docs/guides/dbt-integration.md","sourceDirName":"guides","slug":"/guides/dbt-integration","permalink":"/guides/dbt-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/estuary/flow/edit/master/site/docs/guides/dbt-integration.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Customize Materialized Fields","permalink":"/guides/customize-materialization-fields"},"next":{"title":"Connecting to Estuary Flow from Kafka using Dekaf","permalink":"/guides/dekaf_reading_collections_from_kafka"}}');var a=n(74848),r=n(28453);const s={},o="dbt Cloud Integration",l={},d=[{value:"How to Configure dbt Cloud Integration",id:"how-to-configure-dbt-cloud-integration",level:2},{value:"Required Parameters",id:"required-parameters",level:3},{value:"Optional Parameters",id:"optional-parameters",level:3},{value:"Use Cases",id:"use-cases",level:2},{value:"Regular Data Transformation on New Data",id:"regular-data-transformation-on-new-data",level:3},{value:"Job Management",id:"job-management",level:3}];function c(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"dbt-cloud-integration",children:"dbt Cloud Integration"})}),"\n",(0,a.jsx)(t.p,{children:"Estuary Flow offers an integration with dbt Cloud, enabling users to trigger dbt jobs automatically when new data\nis available in a materialized view. This integration provides orchestration between the data ingestion and\ntransformation layers, making real-time data workflows more efficient and automating data transformations."}),"\n",(0,a.jsx)(t.p,{children:"With the dbt Cloud Job Trigger feature in Estuary Flow, you can:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"Automate transformations with dbt jobs as soon as new data is materialized, ensuring data freshness in your analytics."}),"\n",(0,a.jsx)(t.li,{children:"Specify custom job behavior, like replacing or skipping jobs if a trigger is already in progress."}),"\n",(0,a.jsx)(t.li,{children:'Define a custom "cause" message to add context for each triggered job.'}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"The integration can be configured when creating or editing a Materialization."}),"\n",(0,a.jsx)(t.h2,{id:"how-to-configure-dbt-cloud-integration",children:"How to Configure dbt Cloud Integration"}),"\n",(0,a.jsx)(t.p,{children:"Follow these steps to configure the dbt Cloud Job Trigger within an Estuary Flow materialization connector:"}),"\n",(0,a.jsx)(t.h3,{id:"required-parameters",children:"Required Parameters"}),"\n",(0,a.jsx)(t.p,{children:"To configure the dbt Cloud Job Trigger, you\u2019ll need the following information:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["Access URL: The dbt access URL can be found in your dbt Account Settings. Use this URL if your dbt account requires a\nspecific access endpoint. For more information, visit go.estuary.dev/dbt-cloud-trigger. If you have not yet migrated\nto the new API, your Access URL is: ",(0,a.jsx)(t.a,{href:"https://cloud.getdbt.com/",children:"https://cloud.getdbt.com/"})]}),"\n",(0,a.jsx)(t.li,{children:"Job ID: The unique identifier for the dbt job you wish to trigger."}),"\n",(0,a.jsx)(t.li,{children:"Account ID: Your dbt account identifier."}),"\n",(0,a.jsx)(t.li,{children:"API Key: The dbt API key associated with your account. This allows Estuary Flow to authenticate with dbt Cloud and\ntrigger jobs."}),"\n"]}),"\n",(0,a.jsx)(t.h3,{id:"optional-parameters",children:"Optional Parameters"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:'Cause Message: Set a custom message that will appear as the "cause" for each triggered job. This is useful for\ntracking the context of each run, especially in complex workflows. If left empty, it defaults to "Estuary Flow."'}),"\n",(0,a.jsxs)(t.li,{children:["Job Trigger Mode:","\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"skip: Skips the trigger if a job is already running (default)."}),"\n",(0,a.jsx)(t.li,{children:"replace: Cancels any currently running job and starts a new one."}),"\n",(0,a.jsx)(t.li,{children:"ignore: Initiates a new job regardless of any existing jobs."}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(t.li,{children:"Run Interval: Defines the interval at which the dbt job should run. This interval only triggers if new data has been\nmaterialized. The default is 30m (30 minutes)."}),"\n"]}),"\n",(0,a.jsx)(t.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,a.jsx)(t.h3,{id:"regular-data-transformation-on-new-data",children:"Regular Data Transformation on New Data"}),"\n",(0,a.jsxs)(t.p,{children:["In scenarios where data arrival may be delayed (for example, a materialization connector's ",(0,a.jsx)(t.code,{children:"Sync Frequency"})," is set to\n",(0,a.jsx)(t.code,{children:"1hr"}),"), the dbt Cloud Job Trigger mechanism in Estuary Flow is designed to ensure transformations are consistent without\noverwhelming the dbt job queue. Here\u2019s how the process works:"]}),"\n",(0,a.jsxs)(t.ol,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Connector Initialization: When the connector starts, it immediately triggers a dbt job. This initial job ensures that\ndata is consistent, even if the connector has restarted."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:["Materializing Initial Data: The connector materializes an initial chunk of data and then starts a timer, set to\ntrigger the dbt job in a specified interval (",(0,a.jsx)(t.code,{children:"Run Interval"}),")."]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Handling Subsequent Data Chunks: The connector continues materializing the remaining data chunks and, after\ncompleting the initial data load, starts a scheduled delay (e.g., 1 hour if no new data is arriving)."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"dbt Job Trigger Timing: The dbt job triggers once the set interval (e.g., 30 minutes) has passed from the initial\ntimer, regardless of whether there is backfilled data."}),"\n",(0,a.jsxs)(t.ol,{children:["\n",(0,a.jsx)(t.li,{children:"If the data arrival is sparse or infrequent, such as once per day, the default 30-minute interval allows for\ntimely but controlled job triggers without excessive job runs."}),"\n",(0,a.jsx)(t.li,{children:"During periods without backfilling, the 30-minute interval provides a balance\u2014triggering jobs at regular\nintervals while avoiding rapid job initiation and reducing load on the dbt Cloud system."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:["Minimizing Latency: The ",(0,a.jsx)(t.code,{children:"Run Interval"})," ensures that the dbt job runs shortly after the first bulk of data is\ncommitted, without triggering too frequently, particularly during backfills."]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:["Defaulting to a lower (e.g. 30-minute) interval\u2014supports various use cases, such as cases where connectors don\u2019t use\n",(0,a.jsx)(t.code,{children:"Sync Interval"})," or where data arrival is infrequent."]}),"\n",(0,a.jsx)(t.h3,{id:"job-management",children:"Job Management"}),"\n",(0,a.jsx)(t.p,{children:"The default behaviour is to avoid triggering multiple overlapping dbt jobs, set Job Trigger Mode to skip. This way, if a\njob is already running, the trigger will not start a new job, helping you manage resources efficiently."}),"\n",(0,a.jsx)(t.p,{children:"Alternatively, if you need each transformation job to run regardless of current jobs, set Job Trigger Mode to ignore to\ninitiate a new dbt job each time data is materialized."})]})}function u(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>o});var i=n(96540);const a={},r=i.createContext(a);function s(e){const t=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),i.createElement(r.Provider,{value:t},e.children)}}}]);