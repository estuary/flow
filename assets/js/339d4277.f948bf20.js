"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[2142],{28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var i=t(96540);const r={},s=i.createContext(r);function o(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(s.Provider,{value:n},e.children)}},90696:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"reference/Connectors/materialization-connectors/Dekaf/singlestore","title":"SingleStore","description":"This connector materializes Flow collections as Kafka-compatible messages that a SingleStore Kafka consumer can read. SingleStore is a distributed SQL database designed for data-intensive applications,","source":"@site/docs/reference/Connectors/materialization-connectors/Dekaf/singlestore.md","sourceDirName":"reference/Connectors/materialization-connectors/Dekaf","slug":"/reference/Connectors/materialization-connectors/Dekaf/singlestore","permalink":"/reference/Connectors/materialization-connectors/Dekaf/singlestore","draft":false,"unlisted":false,"editUrl":"https://github.com/estuary/flow/edit/master/site/docs/reference/Connectors/materialization-connectors/Dekaf/singlestore.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"RisingWave","permalink":"/reference/Connectors/materialization-connectors/Dekaf/risingwave"},"next":{"title":"StarTree","permalink":"/reference/Connectors/materialization-connectors/Dekaf/startree"}}');var r=t(74848),s=t(28453);const o={},a="SingleStore",l={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Variants",id:"variants",level:2},{value:"Setup",id:"setup",level:2},{value:"Connecting Estuary Flow to SingleStore",id:"connecting-estuary-flow-to-singlestore",level:2},{value:"Configuration",id:"configuration",level:2},{value:"Properties",id:"properties",level:3},{value:"Endpoint",id:"endpoint",level:4},{value:"Bindings",id:"bindings",level:4},{value:"Sample",id:"sample",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"singlestore",children:"SingleStore"})}),"\n",(0,r.jsxs)(n.p,{children:["This connector materializes Flow collections as Kafka-compatible messages that a SingleStore Kafka consumer can read. ",(0,r.jsx)(n.a,{href:"https://www.singlestore.com/",children:"SingleStore"})," is a distributed SQL database designed for data-intensive applications,\noffering high performance for both transactional and analytical workloads."]}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsx)(n.p,{children:"To use this connector, you'll need:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"At least one Flow collection"}),"\n",(0,r.jsx)(n.li,{children:"A SingleStore account"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"variants",children:"Variants"}),"\n",(0,r.jsxs)(n.p,{children:["This connector is a variant of the default Dekaf connector. For other integration options, see the main ",(0,r.jsx)(n.a,{href:"/reference/Connectors/materialization-connectors/Dekaf/",children:"Dekaf"})," page."]}),"\n",(0,r.jsx)(n.h2,{id:"setup",children:"Setup"}),"\n",(0,r.jsx)(n.p,{children:"Provide an auth token when setting up the Dekaf connector. This can be a password of your choosing and will be used to authenticate consumers to your Kafka topics."}),"\n",(0,r.jsxs)(n.p,{children:["Once the connector is created, note the full materialization name, such as ",(0,r.jsx)(n.code,{children:"YOUR-ORG/YOUR-PREFIX/YOUR-MATERIALIZATION"}),". You will use this as the username."]}),"\n",(0,r.jsx)(n.h2,{id:"connecting-estuary-flow-to-singlestore",children:"Connecting Estuary Flow to SingleStore"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"In the SingleStore Cloud Portal, navigate to the SQL Editor section of the Data Studio."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Execute the following script to create a table and an ingestion pipeline to hydrate it."}),"\n",(0,r.jsxs)(n.p,{children:["This example will ingest data from the demo wikipedia collection (",(0,r.jsx)(n.code,{children:"/demo/wikipedia/recentchange-sampled"}),") in Estuary Flow. This becomes the ",(0,r.jsx)(n.code,{children:"recentchange-sampled"})," topic once added to the SingleStore materialization."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:'CREATE TABLE test_table (id NUMERIC, server_name VARCHAR(255), title VARCHAR(255));\n\nCREATE PIPELINE test AS\n        LOAD DATA KAFKA "dekaf.estuary-data.com:9092/recentchange-sampled"\n        CONFIG \'{\n            "security.protocol":"SASL_SSL",\n            "sasl.mechanism":"PLAIN",\n            "sasl.username":"{YOUR/MATERIALIZATION/NAME}",\n            "broker.address.family": "v4",\n            "schema.registry.username": "{YOUR/MATERIALIZATION/NAME}",\n            "fetch.wait.max.ms": "2000"\n        }\'\n        CREDENTIALS \'{\n            "sasl.password": "YOUR_AUTH_TOKEN",\n            "schema.registry.password": "YOUR_AUTH_TOKEN"\n        }\'\n        INTO table test_table\n        FORMAT AVRO SCHEMA REGISTRY \'https://dekaf.estuary-data.com\'\n        ( id <- id, server_name <- server_name, title <- title );\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Your pipeline should now start ingesting data from Estuary Flow into SingleStore."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,r.jsx)(n.p,{children:"To use this connector, begin with data in one or more Flow collections.\nUse the below properties to configure a Dekaf materialization, which will direct one or more of your Flow collections to your desired topics."}),"\n",(0,r.jsx)(n.h3,{id:"properties",children:"Properties"}),"\n",(0,r.jsx)(n.h4,{id:"endpoint",children:"Endpoint"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Property"}),(0,r.jsx)(n.th,{children:"Title"}),(0,r.jsx)(n.th,{children:"Description"}),(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Required/Default"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/token"})}),(0,r.jsx)(n.td,{children:"Auth Token"}),(0,r.jsx)(n.td,{children:"The password that Kafka consumers can use to authenticate to this task."}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{children:"Required"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/strict_topic_names"})}),(0,r.jsx)(n.td,{children:"Strict Topic Names"}),(0,r.jsx)(n.td,{children:"Whether or not to expose topic names in a strictly Kafka-compliant format."}),(0,r.jsx)(n.td,{children:"boolean"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"false"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/deletions"})}),(0,r.jsx)(n.td,{children:"Deletion Mode"}),(0,r.jsxs)(n.td,{children:["Can choose between ",(0,r.jsx)(n.code,{children:"kafka"})," or ",(0,r.jsx)(n.code,{children:"cdc"})," deletion modes."]}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"kafka"})})]})]})]}),"\n",(0,r.jsx)(n.h4,{id:"bindings",children:"Bindings"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Property"}),(0,r.jsx)(n.th,{children:"Title"}),(0,r.jsx)(n.th,{children:"Description"}),(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Required/Default"})]})}),(0,r.jsx)(n.tbody,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/topic_name"})}),(0,r.jsx)(n.td,{children:"Topic Name"}),(0,r.jsx)(n.td,{children:"Kafka topic name that Dekaf will publish under."}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{children:"Required"})]})})]}),"\n",(0,r.jsx)(n.h3,{id:"sample",children:"Sample"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"materializations:\n  ${PREFIX}/${mat_name}:\n    endpoint:\n      dekaf:\n        config:\n          token: <auth-token>\n          strict_topic_names: false\n          deletions: kafka\n        variant: singlestore\n    bindings:\n      - resource:\n          topic_name: ${COLLECTION_NAME}\n        source: ${PREFIX}/${COLLECTION_NAME}\n"})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);