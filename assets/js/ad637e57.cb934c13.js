"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[9325],{4166:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>a});const o=JSON.parse('{"id":"reference/Connectors/capture-connectors/MongoDB/mongodb","title":"MongoDB","description":"This connector captures data from your MongoDB collections into Flow collections.","source":"@site/docs/reference/Connectors/capture-connectors/MongoDB/mongodb.md","sourceDirName":"reference/Connectors/capture-connectors/MongoDB","slug":"/reference/Connectors/capture-connectors/MongoDB/","permalink":"/reference/Connectors/capture-connectors/MongoDB/","draft":false,"unlisted":false,"editUrl":"https://github.com/estuary/flow/edit/master/site/docs/reference/Connectors/capture-connectors/MongoDB/mongodb.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Monday","permalink":"/reference/Connectors/capture-connectors/monday"},"next":{"title":"Amazon DocumentDB","permalink":"/reference/Connectors/capture-connectors/MongoDB/amazon-documentdb"}}');var s=t(74848),r=t(28453);const i={},c="MongoDB",d={},a=[{value:"Supported platforms",id:"supported-platforms",level:2},{value:"Data model",id:"data-model",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Capture Modes",id:"capture-modes",level:2},{value:"Configuration",id:"configuration",level:2},{value:"Properties",id:"properties",level:3},{value:"Endpoint",id:"endpoint",level:4},{value:"Bindings",id:"bindings",level:4},{value:"Sample",id:"sample",level:3},{value:"SSH Tunneling",id:"ssh-tunneling",level:2},{value:"Backfill and real-time updates",id:"backfill-and-real-time-updates",level:2},{value:"Change Event Pre- and Post-Images",id:"change-event-pre--and-post-images",level:2}];function l(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"mongodb",children:"MongoDB"})}),"\n",(0,s.jsx)(n.p,{children:"This connector captures data from your MongoDB collections into Flow collections."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://ghcr.io/estuary/source-mongodb:dev",children:(0,s.jsx)(n.code,{children:"ghcr.io/estuary/source-mongodb:dev"})})," provides the\nlatest connector image. You can also follow the link in your browser to see past image versions."]}),"\n",(0,s.jsx)(n.h2,{id:"supported-platforms",children:"Supported platforms"}),"\n",(0,s.jsx)(n.p,{children:"The MongoDB connector has a couple variants to support additional document-based database options. Continue reading this page for standard MongoDB setup or see one of the following:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/reference/Connectors/capture-connectors/MongoDB/amazon-documentdb",children:"Amazon DocumentDB"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/reference/Connectors/capture-connectors/MongoDB/azure-cosmosdb",children:"Azure Cosmos DB"})}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"data-model",children:"Data model"}),"\n",(0,s.jsxs)(n.p,{children:["MongoDB is a NoSQL database. Its ",(0,s.jsx)(n.a,{href:"https://www.mongodb.com/docs/manual/core/data-modeling-introduction/",children:"data\nmodel"})," consists of\n",(0,s.jsx)(n.strong,{children:"documents"})," (lightweight records that contain mappings of fields and values) organized in\n",(0,s.jsx)(n.strong,{children:"collections"}),". MongoDB documents have a mandatory ",(0,s.jsx)(n.code,{children:"_id"})," field that is used as the key of the\ncollection."]}),"\n",(0,s.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsx)(n.p,{children:"You'll need:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Credentials for connecting to your MongoDB instance and database."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Read access to your MongoDB database(s), see ",(0,s.jsx)(n.a,{href:"https://www.mongodb.com/docs/manual/core/authorization/",children:"Role-Based Access\nControl"})," for more information."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{title:"Configuration Tip",type:"tip",children:(0,s.jsxs)(n.p,{children:["If you are using a user with access to all databases, then in your mongodb address, you must specify\n",(0,s.jsx)(n.code,{children:"?authSource=admin"})," parameter so that authentication is done through your admin database."]})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["If you are using MongoDB Atlas, or your MongoDB provider requires allowlisting of IPs, you need to\n",(0,s.jsx)(n.a,{href:"/reference/allow-ip-addresses",children:"allowlist the Estuary IP addresses"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"capture-modes",children:"Capture Modes"}),"\n",(0,s.jsxs)(n.p,{children:["MongoDB ",(0,s.jsx)(n.a,{href:"https://www.mongodb.com/docs/manual/changeStreams/",children:"change streams"})," are\nthe preferred way to capture on-going changes to collections. Change streams\nallow capturing real-time events representing new documents in your collections,\nupdates to existing documents, and deletions of documents. If change streams are\nenabled on the MongoDB instance/deployment you are connecting to, they will be\nused preferentially for capturing changes."]}),"\n",(0,s.jsxs)(n.p,{children:['An alternate "batch" mode of capturing documents can be used for deployments\nthat do not support change streams, and for MongoDB collection types that do not\nsupport change streams (',(0,s.jsx)(n.a,{href:"https://www.mongodb.com/docs/manual/core/views/",children:"views"}),"\nand ",(0,s.jsx)(n.a,{href:"https://www.mongodb.com/docs/manual/core/timeseries-collections/",children:"time\nseries"}),"\ncollections). The capture mode is configured on a per-collection level in the\n",(0,s.jsx)(n.strong,{children:"Bindings"})," configuration and can be one of the following:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Change Stream Incremental"}),": This is the preferred mode and uses change streams to capture change events."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Batch Snapshot"}),': Performs a "full refresh" by scanning the entire MongoDB\ncollection on a set schedule. A cursor field must be configured, which should\nusually be the ',(0,s.jsx)(n.code,{children:"_id"})," field."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Batch Incremental"}),": Performs a scan on a set schedule where only documents\nhaving a higher cursor field value than previously observed are captured. This\nmode should be used for append-only collections, or where a field value is\nknown to be strictly increasing for all document insertions and updates."]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{title:"Using Cursor Fields",type:"tip",children:(0,s.jsxs)(n.p,{children:["For best performance the selected cursor field should have an\n",(0,s.jsx)(n.a,{href:"https://www.mongodb.com/docs/manual/indexes/",children:"index"}),". This ensures backfill\nqueries are able to be run efficiently, since they require sorting the\ncollection based on the cursor field."]})}),"\n",(0,s.jsx)(n.admonition,{title:"Time Series Collections",type:"tip",children:(0,s.jsxs)(n.p,{children:["Time series collections do ",(0,s.jsx)(n.em,{children:"not"})," have a default index on the ",(0,s.jsx)(n.code,{children:"_id"}),", but do have\nan index on the ",(0,s.jsx)(n.code,{children:"timeField"})," for the collection. This makes the ",(0,s.jsx)(n.code,{children:"timeField"})," a\ngood choice for an incremental cursor if new documents are only ever added to\nthe collection with strictly increasing values for the ",(0,s.jsx)(n.code,{children:"timeField"}),". The capture\nconnector will automatically discover time series collections in ",(0,s.jsx)(n.strong,{children:"Batch\nIncremental"})," mode with the cursor set to the collection's ",(0,s.jsx)(n.code,{children:"timeField"}),"."]})}),"\n",(0,s.jsxs)(n.p,{children:["Only the ",(0,s.jsx)(n.strong,{children:"Change Stream Incremental"})," mode is capable of capturing deletion\nevents. ",(0,s.jsx)(n.strong,{children:"Batch Snapshot"})," will capture updates by virtue of it re-capturing the\nentire source collection periodically. ",(0,s.jsx)(n.strong,{children:"Batch Incremental"})," ",(0,s.jsx)(n.em,{children:"may"})," capture\nupdates to documents if updated documents have strictly increasing values for\nthe cursor field."]}),"\n",(0,s.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,s.jsxs)(n.p,{children:["You configure connectors either in the Flow web app, or by directly editing the Flow specification\nfile. See ",(0,s.jsx)(n.a,{href:"/concepts/connectors#using-connectors",children:"connectors"})," to learn more about using\nconnectors. The values and specification sample below provide configuration details specific to the\nMongoDB source connector."]}),"\n",(0,s.jsx)(n.h3,{id:"properties",children:"Properties"}),"\n",(0,s.jsx)(n.h4,{id:"endpoint",children:"Endpoint"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Property"}),(0,s.jsx)(n.th,{children:"Title"}),(0,s.jsx)(n.th,{children:"Description"}),(0,s.jsx)(n.th,{children:"Type"}),(0,s.jsx)(n.th,{children:"Required/Default"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"/address"})})}),(0,s.jsx)(n.td,{children:"Address"}),(0,s.jsx)(n.td,{children:"Host and port of the database. Optionally can specify scheme for the URL such as mongodb+srv://host."}),(0,s.jsx)(n.td,{children:"string"}),(0,s.jsx)(n.td,{children:"Required"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"/user"})})}),(0,s.jsx)(n.td,{children:"User"}),(0,s.jsx)(n.td,{children:"Database user to connect as."}),(0,s.jsx)(n.td,{children:"string"}),(0,s.jsx)(n.td,{children:"Required"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"/password"})})}),(0,s.jsx)(n.td,{children:"Password"}),(0,s.jsx)(n.td,{children:"Password for the specified database user."}),(0,s.jsx)(n.td,{children:"string"}),(0,s.jsx)(n.td,{children:"Required"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"/database"})}),(0,s.jsx)(n.td,{children:"Database"}),(0,s.jsx)(n.td,{children:"Optional comma-separated list of the databases to discover. If not provided will discover all available databases in the instance."}),(0,s.jsx)(n.td,{children:"string"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"/batchAndChangeStream"})}),(0,s.jsx)(n.td,{children:"Capture Batch Collections in Addition to Change Stream Collections"}),(0,s.jsx)(n.td,{children:"Discover collections that can only be batch captured if the deployment supports change streams. Check this box to capture views and time series collections as well as change streams. All collections will be captured in batch mode if the server does not support change streams regardless of this setting."}),(0,s.jsx)(n.td,{children:"boolean"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"/pollSchedule"})}),(0,s.jsx)(n.td,{children:"Default Batch Collection Polling Schedule"}),(0,s.jsx)(n.td,{children:"When and how often to poll batch collections. Accepts a Go duration string like '5m' or '6h' for frequency-based polling or a string like 'daily at 12:34Z' to poll at a specific time (specified in UTC) every day. Defaults to '24h' if unset"}),(0,s.jsx)(n.td,{children:"string"}),(0,s.jsx)(n.td,{})]})]})]}),"\n",(0,s.jsx)(n.h4,{id:"bindings",children:"Bindings"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Property"}),(0,s.jsx)(n.th,{children:"Title"}),(0,s.jsx)(n.th,{children:"Description"}),(0,s.jsx)(n.th,{children:"Type"}),(0,s.jsx)(n.th,{children:"Required/Default"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"/database"})})}),(0,s.jsx)(n.td,{children:"Database"}),(0,s.jsx)(n.td,{children:"Database name"}),(0,s.jsx)(n.td,{children:"string"}),(0,s.jsx)(n.td,{children:"Required"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"/collection"})})}),(0,s.jsx)(n.td,{children:"Stream"}),(0,s.jsx)(n.td,{children:"Collection name"}),(0,s.jsx)(n.td,{children:"string"}),(0,s.jsx)(n.td,{children:"Required"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"/captureMode"})}),(0,s.jsx)(n.td,{children:"Capture Mode"}),(0,s.jsxs)(n.td,{children:["Either ",(0,s.jsx)(n.strong,{children:"Change Stream Incremental"}),", ",(0,s.jsx)(n.strong,{children:"Batch Snapshot"}),", or ",(0,s.jsx)(n.strong,{children:"Batch Incremental"})]}),(0,s.jsx)(n.td,{children:"string"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"/cursorField"})}),(0,s.jsx)(n.td,{children:"Cursor Field"}),(0,s.jsx)(n.td,{children:"The name of the field to use as a cursor for batch-mode bindings. For best performance this field should be indexed. When used with 'Batch Incremental' mode documents added to the collection are expected to always have the cursor field and for it to be strictly increasing."}),(0,s.jsx)(n.td,{children:"string"}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"/pollSchedule"})}),(0,s.jsx)(n.td,{children:"Polling Schedule"}),(0,s.jsx)(n.td,{children:"When and how often to poll batch collections (overrides the connector default setting). Accepts a Go duration string like '5m' or '6h' for frequency-based polling or a string like 'daily at 12:34Z' to poll at a specific time (specified in UTC) every day. Defaults to '24h' if unset."}),(0,s.jsx)(n.td,{children:"string"}),(0,s.jsx)(n.td,{})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"sample",children:"Sample"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'captures:\n  ${PREFIX}/${CAPTURE_NAME}:\n    endpoint:\n      connector:\n        image: ghcr.io/estuary/source-mongodb:dev\n        config:\n          address: "mongo:27017"\n          password: "flow"\n          user: "flow"\n    bindings:\n      - resource:\n          collection: users\n          database: test\n        target: ${PREFIX}/users\n'})}),"\n",(0,s.jsx)(n.h2,{id:"ssh-tunneling",children:"SSH Tunneling"}),"\n",(0,s.jsx)(n.p,{children:"As an alternative to connecting to your MongoDB instance directly, you can allow secure connections via SSH tunneling. To do so:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Refer to the ",(0,s.jsx)(n.a,{href:"/guides/connect-network",children:"guide"})," to configure an SSH server on the cloud platform of your choice."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Configure your connector as described in the ",(0,s.jsx)(n.a,{href:"#configuration",children:"configuration"})," section above, with the addition of the ",(0,s.jsx)(n.code,{children:"networkTunnel"})," stanza to enable the SSH tunnel, if using. See ",(0,s.jsx)(n.a,{href:"/concepts/connectors#connecting-to-endpoints-on-secure-networks",children:"Connecting to endpoints on secure networks"})," for additional details and a sample."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"backfill-and-real-time-updates",children:"Backfill and real-time updates"}),"\n",(0,s.jsxs)(n.p,{children:["When performing the initial database snapshot, the connector continuously reads from ",(0,s.jsx)(n.a,{href:"https://www.mongodb.com/docs/manual/changeStreams/",children:(0,s.jsx)(n.strong,{children:"change\nstreams"})})," to capture change events while\nexecuting collection scans to backfill pre-existing documents. After the initial snapshot, the\nconnector continues to read from the change streams indefinitely to capture all changes going\nforward."]}),"\n",(0,s.jsxs)(n.p,{children:["If the connector's process is paused for a while, it will attempt to resume capturing change events\nfrom where it left off, however the connector's ability to do this depends on the size of the\n",(0,s.jsx)(n.a,{href:"https://www.mongodb.com/docs/manual/core/replica-set-oplog/",children:"replica set oplog"}),", and in certain\ncircumstances, when the pause has been long enough for the oplog to have evicted old change events,\nthe connector will need to re-do the backfill to ensure data consistency. In these cases it is\nnecessary to ",(0,s.jsx)(n.a,{href:"https://www.mongodb.com/docs/manual/tutorial/change-oplog-size/#c.-change-the-oplog-size-of-the-replica-set-member",children:"resize your\noplog"}),"\nor ",(0,s.jsx)(n.a,{href:"https://www.mongodb.com/docs/manual/reference/command/replSetResizeOplog/#minimum-oplog-retention-period",children:"set a minimum retention\nperiod"}),"\nfor your oplog to be able to reliably capture data. The recommended minimum retention period is at\nleast 24 hours, but we recommend higher values to improve reliability."]}),"\n",(0,s.jsx)(n.h2,{id:"change-event-pre--and-post-images",children:"Change Event Pre- and Post-Images"}),"\n",(0,s.jsxs)(n.p,{children:["Captured documents for change events from ",(0,s.jsx)(n.code,{children:"update"})," operations will always\ninclude a full post-image, since the change stream is configured with the ",(0,s.jsxs)(n.a,{href:"https://www.mongodb.com/docs/manual/changeStreams/#lookup-full-document-for-update-operations",children:[(0,s.jsx)(n.code,{children:"{ fullDocument: 'updateLookup' }"}),"\nsetting"]}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["Pre-images for ",(0,s.jsx)(n.code,{children:"update"}),", ",(0,s.jsx)(n.code,{children:"replace"}),", and ",(0,s.jsx)(n.code,{children:"delete"})," operations will be captured if\nthey are available. For these pre-images to be captured, the source MongoDB\ncollection must have ",(0,s.jsx)(n.code,{children:"changeStreamPreAndPostImages"})," enabled. See the ",(0,s.jsx)(n.a,{href:"https://www.mongodb.com/docs/manual/changeStreams/#change-streams-with-document-pre--and-post-images",children:"official\nMongoDB\ndocumentation"}),"\nfor more information on how to enable this setting."]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>c});var o=t(96540);const s={},r=o.createContext(s);function i(e){const n=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);