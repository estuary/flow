"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[3073],{28453:(e,n,s)=>{s.d(n,{R:()=>c,x:()=>o});var t=s(96540);const r={},i=t.createContext(r);function c(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:c(e.components),t.createElement(i.Provider,{value:n},e.children)}},56540:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>c,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"reference/Connectors/capture-connectors/apache-kafka","title":"Apache Kafka","description":"This connector captures streaming data from Apache Kafka topics.","source":"@site/docs/reference/Connectors/capture-connectors/apache-kafka.md","sourceDirName":"reference/Connectors/capture-connectors","slug":"/reference/Connectors/capture-connectors/apache-kafka","permalink":"/reference/Connectors/capture-connectors/apache-kafka","draft":false,"unlisted":false,"editUrl":"https://github.com/estuary/flow/edit/master/site/docs/reference/Connectors/capture-connectors/apache-kafka.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Amplitude","permalink":"/reference/Connectors/capture-connectors/amplitude"},"next":{"title":"Apple App Store","permalink":"/reference/Connectors/capture-connectors/apple-app-store"}}');var r=s(74848),i=s(28453);const c={},o="Apache Kafka",a={},d=[{value:"Supported message formats",id:"supported-message-formats",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Discovered collection schemas",id:"discovered-collection-schemas",level:3},{value:"Authentication and connection security",id:"authentication-and-connection-security",level:3},{value:"AWS Managed Streaming Kafka (MSK)",id:"aws-managed-streaming-kafka-msk",level:3},{value:"Configuration",id:"configuration",level:2},{value:"Properties",id:"properties",level:3},{value:"Endpoint",id:"endpoint",level:4},{value:"Bindings",id:"bindings",level:4},{value:"Sample",id:"sample",level:3}];function l(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"apache-kafka",children:"Apache Kafka"})}),"\n",(0,r.jsx)(n.p,{children:"This connector captures streaming data from Apache Kafka topics."}),"\n",(0,r.jsxs)(n.p,{children:["It is available for use in the Flow web application. For local development or open-source workflows, ",(0,r.jsx)(n.a,{href:"https://github.com/estuary/connectors/pkgs/container/source-kafka",children:(0,r.jsx)(n.code,{children:"ghcr.io/estuary/source-kafka:dev"})})," provides the latest version of the connector as a Docker image. You can also follow the link in your browser to see past image versions."]}),"\n",(0,r.jsx)(n.h2,{id:"supported-message-formats",children:"Supported message formats"}),"\n",(0,r.jsx)(n.p,{children:"This connectors supports Kafka messages encoded in Avro or JSON format."}),"\n",(0,r.jsxs)(n.p,{children:["For Avro messages, the connector must be configured to use a ",(0,r.jsx)(n.a,{href:"https://docs.confluent.io/platform/current/schema-registry/index.html",children:"schema\nregistry"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"JSON messages may be read without a schema registry. If the JSON messages were\nencoded with a JSON schema, configuring a schema registry is recommended to\nenable discovery of collection keys if the message key has an associated schema."}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["A Kafka cluster with:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"https://kafka.apache.org/documentation/#producerconfigs_bootstrap.servers",children:"bootstrap.servers"})," configured so that clients may connect via the desired host and port"]}),"\n",(0,r.jsx)(n.li,{children:"An authentication mechanism of choice set up (highly recommended for production environments)"}),"\n",(0,r.jsx)(n.li,{children:"Connection security enabled with TLS (highly recommended for production environments)"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["If using schema registry:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"The endpoint to use for connecting to the schema registry"}),"\n",(0,r.jsx)(n.li,{children:"Username for authentication"}),"\n",(0,r.jsx)(n.li,{children:"Password for authentication"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Flat schemas, i.e. no use of schema references (",(0,r.jsx)(n.code,{children:"import"}),", ",(0,r.jsx)(n.code,{children:"$ref"}),"), as these are not currently supported"]}),"\n"]}),"\n",(0,r.jsx)(n.admonition,{type:"tip",children:(0,r.jsxs)(n.p,{children:["If you are using the Confluent Cloud Schema Registry, your schema registry\nusername and password will be the ",(0,r.jsx)(n.strong,{children:"key"})," and ",(0,r.jsx)(n.strong,{children:"secret"})," from your schema\nregistry API key. See the ",(0,r.jsx)(n.a,{href:"https://docs.confluent.io/cloud/current/get-started/schema-registry.html#create-an-api-key-for-ccloud-sr",children:"Confluent Cloud Schema Registry\nDocumentation"}),"\nfor help setting up a schema registry API key."]})}),"\n",(0,r.jsx)(n.h3,{id:"discovered-collection-schemas",children:"Discovered collection schemas"}),"\n",(0,r.jsxs)(n.p,{children:["If no schema registry is configured, all available topics will be discovered and\nuse a collection key composed of the captured message's ",(0,r.jsx)(n.code,{children:"partition"})," and\n",(0,r.jsx)(n.code,{children:"offset"}),". If schema registry is configured, Flow collections for Kafka topics\nwill be discovered using the ",(0,r.jsx)(n.em,{children:"latest"})," version of the registered key schema for\nthe topic."]}),"\n",(0,r.jsxs)(n.p,{children:["For a collection key to be discovered from a registered topic key schema, the\ntopic key schema must be compatible with a ",(0,r.jsx)(n.a,{href:"/concepts/collections#keys",children:"Flow collection\nkey"}),", with the following additional considerations:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Key fields must not contain ",(0,r.jsx)(n.code,{children:"null"})," as a type"]}),"\n",(0,r.jsx)(n.li,{children:"Key fields can be a single type only"}),"\n",(0,r.jsx)(n.li,{children:"Keys may contain nested fields, such as types with nested Avro records"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["If a topic has a registered key schema but it does not fit these requirements,\nthe default collection key of ",(0,r.jsx)(n.code,{children:"parition"})," and ",(0,r.jsx)(n.code,{children:"offset"})," will be used instead."]}),"\n",(0,r.jsx)(n.h3,{id:"authentication-and-connection-security",children:"Authentication and connection security"}),"\n",(0,r.jsx)(n.p,{children:"Neither authentication nor connection security are enabled by default in your Kafka cluster, but both are important considerations.\nSimilarly, Flow's Kafka connectors do not strictly require authentication or connection security mechanisms.\nYou may choose to omit them for local development and testing; however, both are strongly encouraged for production environments."}),"\n",(0,r.jsxs)(n.p,{children:["A wide ",(0,r.jsx)(n.a,{href:"https://kafka.apache.org/documentation/#security_overview",children:"variety of authentication methods"})," is available in Kafka clusters.\nFlow supports SASL/SCRAM-SHA-256, SASL/SCRAM-SHA-512, and SASL/PLAIN. Behavior using other authentication methods is not guaranteed.\nWhen authentication details are not provided, the client connection will attempt to use PLAINTEXT (insecure) protocol."]}),"\n",(0,r.jsxs)(n.p,{children:["If you don't already have authentication enabled on your cluster, Estuary recommends either of listed ",(0,r.jsx)(n.a,{href:"https://kafka.apache.org/documentation/#security_sasl_scram",children:"SASL/SCRAM"})," methods.\nWith SCRAM, you set up a username and password, making it analogous to the traditional authentication mechanisms\nyou use in other applications."]}),"\n",(0,r.jsx)(n.admonition,{type:"tip",children:(0,r.jsxs)(n.p,{children:["If you are connecting to Kafka hosted on Confluent Cloud, select the ",(0,r.jsx)(n.strong,{children:"PLAIN"}),"\nSASL mechanism."]})}),"\n",(0,r.jsxs)(n.p,{children:['For connection security, Estuary recommends that you enable TLS encryption for your SASL mechanism of choice,\nas well as all other components of your cluster.\nNote that because TLS replaced now-deprecated SSL encryption, Kafka still uses the acronym "SSL" to refer to TLS encryption.\nSee ',(0,r.jsx)(n.a,{href:"https://docs.confluent.io/platform/current/kafka/authentication_ssl.html",children:"Confluent's documentation"})," for details."]}),"\n",(0,r.jsx)(n.admonition,{title:"Beta",type:"info",children:(0,r.jsx)(n.p,{children:"TLS encryption is currently the only supported connection security mechanism for this connector.\nOther connection security methods may be enabled in the future."})}),"\n",(0,r.jsx)(n.h3,{id:"aws-managed-streaming-kafka-msk",children:"AWS Managed Streaming Kafka (MSK)"}),"\n",(0,r.jsxs)(n.p,{children:["If using AWS Managed Streaming for Apache Kafka (MSK), you can use IAM authentication with our connector. Read more about IAM authentication with MSK in AWS docs: ",(0,r.jsx)(n.a,{href:"https://docs.aws.amazon.com/msk/latest/developerguide/iam-access-control.html",children:"IAM access control"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["Additionally, you want to make sure that your VPC configuration allows inbound and outbound requests to ",(0,r.jsx)(n.a,{href:"/reference/allow-ip-addresses",children:"Estuary Flow IP addresses"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,r.jsxs)(n.p,{children:["You configure connectors either in the Flow web app, or by directly editing the catalog specification file.\nSee ",(0,r.jsx)(n.a,{href:"/concepts/connectors#using-connectors",children:"connectors"})," to learn more about using connectors. The values and specification sample below provide configuration details specific to the Apache Kafka source connector."]}),"\n",(0,r.jsx)(n.h3,{id:"properties",children:"Properties"}),"\n",(0,r.jsx)(n.h4,{id:"endpoint",children:"Endpoint"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Property"}),(0,r.jsx)(n.th,{children:"Title"}),(0,r.jsx)(n.th,{children:"Description"}),(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Required/Default"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"/bootstrap_servers"})})}),(0,r.jsx)(n.td,{children:"Bootstrap servers"}),(0,r.jsx)(n.td,{children:"The initial servers in the Kafka cluster to connect to, separated by commas. The Kafka client will be informed of the rest of the cluster nodes by connecting to one of these nodes."}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{children:"Required"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"/tls"})})}),(0,r.jsx)(n.td,{children:"TLS"}),(0,r.jsx)(n.td,{children:"TLS connection settings."}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:'"system_certificates"'})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/credentials"})}),(0,r.jsx)(n.td,{children:"Credentials"}),(0,r.jsx)(n.td,{children:"Connection details used to authenticate a client connection to Kafka via SASL."}),(0,r.jsx)(n.td,{children:"null, object"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/credentials/auth_type"})}),(0,r.jsx)(n.td,{children:"Authentication type"}),(0,r.jsxs)(n.td,{children:["One of ",(0,r.jsx)(n.code,{children:"UserPassword"})," for SASL or ",(0,r.jsx)(n.code,{children:"AWS"})," for IAM authentication"]}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/credentials/mechanism"})}),(0,r.jsx)(n.td,{children:"SASL Mechanism"}),(0,r.jsx)(n.td,{children:"SASL mechanism describing how to exchange and authenticate client servers."}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/credentials/password"})}),(0,r.jsx)(n.td,{children:"Password"}),(0,r.jsx)(n.td,{children:"Password, if applicable for the authentication mechanism chosen."}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/credentials/username"})}),(0,r.jsx)(n.td,{children:"Username"}),(0,r.jsx)(n.td,{children:"Username, if applicable for the authentication mechanism chosen."}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/credentials/aws_access_key_id"})}),(0,r.jsx)(n.td,{children:"AWS Access Key ID"}),(0,r.jsx)(n.td,{children:"Supply if using auth_type: AWS"}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/credentials/aws_secret_access_key"})}),(0,r.jsx)(n.td,{children:"AWS Secret Access Key"}),(0,r.jsx)(n.td,{children:"Supply if using auth_type: AWS"}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/credentials/region"})}),(0,r.jsx)(n.td,{children:"AWS Region"}),(0,r.jsx)(n.td,{children:"Supply if using auth_type: AWS"}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"/schema_registry"})})}),(0,r.jsx)(n.td,{children:"Schema Registry"}),(0,r.jsx)(n.td,{children:"Connection details for interacting with a schema registry."}),(0,r.jsx)(n.td,{children:"object"}),(0,r.jsx)(n.td,{children:"Required"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"schema_registry/schema_registry_type"})})}),(0,r.jsx)(n.td,{children:"Schema Registry Type"}),(0,r.jsxs)(n.td,{children:["Either ",(0,r.jsx)(n.code,{children:"confluent_schema_registry"})," or ",(0,r.jsx)(n.code,{children:"no_schema_registry"}),"."]}),(0,r.jsx)(n.td,{children:"object"}),(0,r.jsx)(n.td,{children:"Required"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/schema_registry/endpoint"})}),(0,r.jsx)(n.td,{children:"Schema Registry Endpoint"}),(0,r.jsxs)(n.td,{children:["Schema registry API endpoint. For example: ",(0,r.jsx)(n.a,{href:"https://registry-id.us-east-2.aws.confluent.cloud",children:"https://registry-id.us-east-2.aws.confluent.cloud"}),"."]}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/schema_registry/username"})}),(0,r.jsx)(n.td,{children:"Schema Registry Username"}),(0,r.jsx)(n.td,{children:"Schema registry username to use for authentication. If you are using Confluent Cloud, this will be the 'Key' from your schema registry API key."}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/schema_registry/password"})}),(0,r.jsx)(n.td,{children:"Schema Registry Password"}),(0,r.jsx)(n.td,{children:"Schema registry password to use for authentication. If you are using Confluent Cloud, this will be the 'Secret' from your schema registry API key."}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/schema_registry/enable_json_only"})}),(0,r.jsx)(n.td,{children:"Capture Messages in JSON Format Only"}),(0,r.jsx)(n.td,{children:"If no schema registry is configured the capture will attempt to parse all data as JSON, and discovered collections will use a key of the message partition & offset."}),(0,r.jsx)(n.td,{children:"boolean"}),(0,r.jsx)(n.td,{})]})]})]}),"\n",(0,r.jsx)(n.h4,{id:"bindings",children:"Bindings"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Property"}),(0,r.jsx)(n.th,{children:"Title"}),(0,r.jsx)(n.th,{children:"Description"}),(0,r.jsx)(n.th,{children:"Type"}),(0,r.jsx)(n.th,{children:"Required/Default"})]})}),(0,r.jsx)(n.tbody,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"/topic"})})}),(0,r.jsx)(n.td,{children:"Stream"}),(0,r.jsx)(n.td,{children:"Kafka topic name."}),(0,r.jsx)(n.td,{children:"string"}),(0,r.jsx)(n.td,{children:"Required"})]})})]}),"\n",(0,r.jsx)(n.h3,{id:"sample",children:"Sample"}),"\n",(0,r.jsx)(n.p,{children:"User and password authentication (SASL):"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"captures:\n  ${PREFIX}/${CAPTURE_NAME}:\n    endpoint:\n      connector:\n        image: ghcr.io/estuary/source-kafka:dev\n        config:\n          bootstrap_servers: server1:9092,server2:9092\n          tls: system_certificates\n          credentials:\n            auth_type: UserPassword\n            mechanism: SCRAM-SHA-512\n            username: bruce.wayne\n            password: definitely-not-batman\n          schema_registry:\n            schema_registry_type: confluent_schema_registry\n            endpoint: https://schema.registry.com\n            username: schemaregistry.username\n            password: schemaregistry.password\n    bindings:\n      - resource:\n          topic: ${TOPIC_NAME}\n        target: ${PREFIX}/${COLLECTION_NAME}\n"})}),"\n",(0,r.jsx)(n.p,{children:"AWS IAM authentication:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"captures:\n  ${PREFIX}/${CAPTURE_NAME}:\n    endpoint:\n      connector:\n        image: ghcr.io/estuary/source-kafka:dev\n        config:\n          bootstrap_servers: server1:9092,server2:9092\n          tls: system_certificates\n          credentials:\n            auth_type: AWS\n            aws_access_key_id: AK...\n            aws_secret_access_key: secret\n            region: us-east-1\n          schema_registry:\n            schema_registry_type: confluent_schema_registry\n            endpoint: https://schema.registry.com\n            username: schemaregistry.username\n            password: schemaregistry.password\n    bindings:\n      - resource:\n          topic: ${TOPIC_NAME}\n        target: ${PREFIX}/${COLLECTION_NAME}\n"})}),"\n",(0,r.jsx)(n.p,{children:"Your capture definition will likely be more complex, with additional bindings for each Kafka topic."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"/concepts/captures",children:"Learn more about capture definitions."}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}}}]);