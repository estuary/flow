"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[2505],{28453:(e,t,n)=>{n.d(t,{R:()=>c,x:()=>d});var i=n(96540);const s={},r=i.createContext(s);function c(e){const t=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function d(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:c(e.components),i.createElement(r.Provider,{value:t},e.children)}},66453:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>d,default:()=>h,frontMatter:()=>c,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"reference/Connectors/materialization-connectors/amazon-s3-csv","title":"CSV Files in Amazon S3","description":"This connector materializes delta updates of Flow collections into files in an S3 bucket per the CSV format described in RFC-4180.","source":"@site/docs/reference/Connectors/materialization-connectors/amazon-s3-csv.md","sourceDirName":"reference/Connectors/materialization-connectors","slug":"/reference/Connectors/materialization-connectors/amazon-s3-csv","permalink":"/reference/Connectors/materialization-connectors/amazon-s3-csv","draft":false,"unlisted":false,"editUrl":"https://github.com/estuary/flow/edit/master/site/docs/reference/Connectors/materialization-connectors/amazon-s3-csv.md","tags":[],"version":"current","frontMatter":{"description":"This connector materializes delta updates of Flow collections into files in an S3 bucket per the CSV format described in RFC-4180."},"sidebar":"tutorialSidebar","previous":{"title":"Amazon Redshift","permalink":"/reference/Connectors/materialization-connectors/amazon-redshift"},"next":{"title":"Apache Iceberg Tables in Amazon S3  (delta updates)","permalink":"/reference/Connectors/materialization-connectors/amazon-s3-iceberg"}}');var s=n(74848),r=n(28453);const c={description:"This connector materializes delta updates of Flow collections into files in an S3 bucket per the CSV format described in RFC-4180."},d="CSV Files in Amazon S3",l={},o=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Configuration",id:"configuration",level:2},{value:"Properties",id:"properties",level:3},{value:"Endpoint",id:"endpoint",level:4},{value:"Bindings",id:"bindings",level:4},{value:"Sample",id:"sample",level:3},{value:"File Names",id:"file-names",level:2},{value:"Eventual Consistency",id:"eventual-consistency",level:2}];function a(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"csv-files-in-amazon-s3",children:"CSV Files in Amazon S3"})}),"\n",(0,s.jsxs)(t.p,{children:["This connector materializes ",(0,s.jsx)(t.a,{href:"/concepts/materialization#delta-updates",children:"delta updates"})," of\nFlow collections into files in an S3 bucket per the CSV format described in\n",(0,s.jsx)(t.a,{href:"https://www.rfc-editor.org/rfc/rfc4180.html",children:"RFC-4180"}),". The CSV files are compressed using Gzip\ncompression."]}),"\n",(0,s.jsx)(t.p,{children:"The delta updates are batched within Flow, converted to CSV files, and then pushed to the S3 bucket\nat a time interval that you set. Files are limited to a configurable maximum size. Each materialized\nFlow collection will produce many separate files."}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.a,{href:"https://ghcr.io/estuary/materialize-s3-csv:dev",children:(0,s.jsx)(t.code,{children:"ghcr.io/estuary/materialize-s3-csv:dev"})})," provides\nthe latest connector image. You can also follow the link in your browser to see past image versions."]}),"\n",(0,s.jsx)(t.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsx)(t.p,{children:"To use this connector, you'll need:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["An S3 bucket to write files to. See ",(0,s.jsx)(t.a,{href:"https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html",children:"this\nguide"})," for\ninstructions on setting up a new S3 bucket."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["An AWS root, IAM user or role with the\n",(0,s.jsx)(t.a,{href:"https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObject.html",children:(0,s.jsx)(t.code,{children:"s3:PutObject"})})," permission\nfor the S3 bucket."]}),"\n",(0,s.jsxs)(t.p,{children:["When authenticating as user, you'll need the ",(0,s.jsx)(t.strong,{children:"access key"})," and ",(0,s.jsx)(t.strong,{children:"secret access key"}),". See the\n",(0,s.jsx)(t.a,{href:"https://aws.amazon.com/blogs/security/wheres-my-secret-access-key/",children:"AWS blog"})," for help finding\nthese credentials.  When authenticating using a role, you'll need the ",(0,s.jsx)(t.strong,{children:"region"})," and the ",(0,s.jsx)(t.strong,{children:"role\narn"}),".  Follow the steps in the ",(0,s.jsx)(t.a,{href:"/guides/iam-auth/aws",children:"AWS IAM guide"})," to setup the role."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"configuration",children:"Configuration"}),"\n",(0,s.jsx)(t.p,{children:"Use the below properties to configure the materialization, which will direct one or more of your\nFlow collections to your bucket."}),"\n",(0,s.jsx)(t.h3,{id:"properties",children:"Properties"}),"\n",(0,s.jsx)(t.h4,{id:"endpoint",children:"Endpoint"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Property"}),(0,s.jsx)(t.th,{children:"Title"}),(0,s.jsx)(t.th,{children:"Description"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Required/Default"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.code,{children:"/bucket"})})}),(0,s.jsx)(t.td,{children:"Bucket"}),(0,s.jsx)(t.td,{children:"Bucket to store materialized objects."}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{children:"Required"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.code,{children:"/region"})})}),(0,s.jsx)(t.td,{children:"Region"}),(0,s.jsx)(t.td,{children:"Region of the bucket to write to."}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{children:"Required"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.code,{children:"/uploadInterval"})})}),(0,s.jsx)(t.td,{children:"Upload Interval"}),(0,s.jsx)(t.td,{children:"Frequency at which files will be uploaded."}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{children:"5m"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.code,{children:"/credentials/auth_type"})})}),(0,s.jsx)(t.td,{children:"Auth Type"}),(0,s.jsx)(t.td,{children:"Method to use for authentication.  Must be set to either AWSAccessKey or AWSIAM."}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{children:"AWSAccessKey"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"/credentials/awsAccessKeyId"})}),(0,s.jsx)(t.td,{children:"AWS Access Key ID"}),(0,s.jsxs)(t.td,{children:["Access Key ID for writing data to the bucket.  Required when using the ",(0,s.jsx)(t.code,{children:"AWSAccessKey"})," auth type."]}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"/credentials/awsSecretAccessKey"})}),(0,s.jsx)(t.td,{children:"AWS Secret Access key"}),(0,s.jsxs)(t.td,{children:["Secret Access Key for writing data to the bucket.  Required when using the ",(0,s.jsx)(t.code,{children:"AWSAccessKey"})," auth type."]}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"/credentials/aws_role_arn"})}),(0,s.jsx)(t.td,{children:"AWS Role ARN"}),(0,s.jsxs)(t.td,{children:["Role to assume for writing data to the bucket.  Required when using the ",(0,s.jsx)(t.code,{children:"AWSIAM"})," auth type."]}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"/credentials/aws_region"})}),(0,s.jsx)(t.td,{children:"Region"}),(0,s.jsxs)(t.td,{children:["Region of the bucket to write to.  Required when using the ",(0,s.jsx)(t.code,{children:"AWSIAM"})," auth type."]}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"/prefix"})}),(0,s.jsx)(t.td,{children:"Prefix"}),(0,s.jsx)(t.td,{children:"Optional prefix that will be used to store objects."}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"/fileSizeLimit"})}),(0,s.jsx)(t.td,{children:"File Size Limit"}),(0,s.jsx)(t.td,{children:"Approximate maximum size of materialized files in bytes. Defaults to 10737418240 (10 GiB) if blank."}),(0,s.jsx)(t.td,{children:"integer"}),(0,s.jsx)(t.td,{})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"/endpoint"})}),(0,s.jsx)(t.td,{children:"Custom S3 Endpoint"}),(0,s.jsx)(t.td,{children:"The S3 endpoint URI to connect to. Use if you're materializing to a compatible API that isn't provided by AWS. Should normally be left blank."}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"/csvConfig/skipHeaders"})}),(0,s.jsx)(t.td,{children:"Skip Headers"}),(0,s.jsx)(t.td,{children:"Do not write headers to files."}),(0,s.jsx)(t.td,{children:"integer"}),(0,s.jsx)(t.td,{})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"bindings",children:"Bindings"}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Property"}),(0,s.jsx)(t.th,{children:"Title"}),(0,s.jsx)(t.th,{children:"Description"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Required/Default"})]})}),(0,s.jsx)(t.tbody,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.strong,{children:(0,s.jsx)(t.code,{children:"/path"})})}),(0,s.jsx)(t.td,{children:"Path"}),(0,s.jsx)(t.td,{children:"The path that objects will be materialized to."}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{children:"Required"})]})})]}),"\n",(0,s.jsx)(t.h3,{id:"sample",children:"Sample"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-yaml",children:'materializations:\n  ${PREFIX}/${mat_name}:\n    endpoint:\n      connector:\n        image: "ghcr.io/estuary/materialize-s3-csv:dev"\n        config:\n          bucket: bucket\n          awsAccessKeyId: <access_key_id>\n          awsSecretAccessKey: <secret_access_key>\n          region: us-east-2\n          uploadInterval: 5m\n    bindings:\n      - resource:\n          path: ${COLLECTION_NAME}\n        source: ${PREFIX}/${COLLECTION_NAME}\n'})}),"\n",(0,s.jsx)(t.h2,{id:"file-names",children:"File Names"}),"\n",(0,s.jsx)(t.p,{children:"Materialized files are named with monotonically increasing integer values, padded with leading 0's\nso they remain lexically sortable. For example, a set of files may be materialized like this for a\ngiven collection:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:"bucket/prefix/path/v0000000000/00000000000000000000.csv\nbucket/prefix/path/v0000000000/00000000000000000001.csv\nbucket/prefix/path/v0000000000/00000000000000000002.csv\n"})}),"\n",(0,s.jsxs)(t.p,{children:["Here the values for ",(0,s.jsx)(t.strong,{children:"bucket"})," and ",(0,s.jsx)(t.strong,{children:"prefix"})," are from your endpoint configuration. The ",(0,s.jsx)(t.strong,{children:"path"})," is\nspecific to the binding configuration. ",(0,s.jsx)(t.strong,{children:"v0000000000"})," represents the current ",(0,s.jsx)(t.strong,{children:"backfill counter"}),"\nfor binding and will be increased if the binding is re-backfilled, along with the file names\nstarting back over from 0."]}),"\n",(0,s.jsx)(t.h2,{id:"eventual-consistency",children:"Eventual Consistency"}),"\n",(0,s.jsx)(t.p,{children:"In rare circumstances, recently materialized files may be re-written by files with the same name if\nthe materialization shard is interrupted in the middle of processing a Flow transaction and the\ntransaction must be re-started. Files that were committed as part of a completed transaction will\nnever be re-written. In this way, eventually all collection data will be written to files\neffectively-once, although inconsistencies are possible when accessing the most recently written\ndata."})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}}}]);