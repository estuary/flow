#!/bin/bash

# This script generates a SQL migration, which updates the ops catalog template
# and then creates a new publication of the ops catalog for every existing tenant.
# The intended usage for each environment is:
# Locally: ./ops-catalog/generate-migration.sh local | psql 'postgresql://postgres:postgres@localhost:5432/postgres'
# In production: ./ops-catalog/generate-migration.sh prod | psql <prod-postgres-url>
# The required positional argument identifies the specific flow.yaml file to bundle as the template.
# This will be either `template-local.flow.yaml` or `template-prod.flow.yaml`.

set -o errexit
set -o pipefail
set -o nounset

ENVIRONMENT="$1";
if [[ -z "$ENVIRONMENT" ]]; then
	echo "missing required positional argument of 'prod' or 'local'" 1>&2
	exit 1
fi

SCRIPT_DIR=$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )
INPUT_FILENAME="${SCRIPT_DIR}/template-${ENVIRONMENT}.flow.yaml"
# Run the bundled catalog through sed to escape any single quotes that may be present.
# For postgres, this is done by doubling the single quote character (replace ' with '').
BUNDLED_CATALOG="$(flowctl raw bundle --source "$INPUT_FILENAME" | sed "s/'/''/g")"

cat << EOF
-- This migration was generated by ops-catalog/generate-migration.sh
-- It updates the ops catalog template that's used by agent when provisioning new tenants,
-- and also re-publishes the ops catalogs for all existing tenants.
begin;

do \$\$
declare
	bundled_catalog_arg json := '${BUNDLED_CATALOG}';
	ops_user_id uuid;
	current_tenant tenants;
	tenant_count integer;
	collection_specs jsonb := '{}';
	current_l1_stat_rollup integer;
	logs_template jsonb;
	stats_template jsonb;
	new_draft_id flowid := internal.id_generator();
	publication_id flowid := internal.id_generator();
begin

	-- Identify user which owns ops specifications.
	select id into strict ops_user_id from auth.users where email = 'support@estuary.dev';

	-- Update the ops catalog template.
	update ops_catalog_template set bundled_catalog = bundled_catalog_arg;

	-- There must be at least one tenant in the system to proceed. This is a guard for local
	-- development when first starting the local stack.
	select count(*)
	into strict tenant_count
	from tenants;
	if tenant_count = 0 then
		return;
	end if;

	for current_l1_stat_rollup in
		select distinct l1_stat_rollup from tenants
	loop
		collection_specs := collection_specs || internal.create_l1_derivation_spec(bundled_catalog_arg::jsonb, current_l1_stat_rollup);
	end loop;

	collection_specs := collection_specs || internal.create_l2_derivation_spec(bundled_catalog_arg::jsonb);

	logs_template := jsonb_build_object('ops/TENANT/logs', bundled_catalog_arg::jsonb #> '{collections,ops/TENANT/logs}');
	stats_template := jsonb_build_object('ops/TENANT/stats', bundled_catalog_arg::jsonb #> '{collections,ops/TENANT/stats}');

	for current_tenant in
		select * from tenants
	loop
		collection_specs := collection_specs || replace(logs_template::text, 'TENANT', rtrim(current_tenant.tenant, '/'))::jsonb;
		collection_specs := collection_specs || replace(stats_template::text, 'TENANT', rtrim(current_tenant.tenant, '/'))::jsonb;
	end loop;

	insert into drafts (id, user_id, detail) values
	(new_draft_id, ops_user_id, 're-publishing ops catalog');

	insert into publications (id, user_id, draft_id) values
	(publication_id, ops_user_id, new_draft_id);

	insert into draft_specs (draft_id, catalog_name, spec_type, spec)
	select new_draft_id, "key", 'collection'::catalog_spec_type, "value"
	from jsonb_each(collection_specs)
	union all
	select new_draft_id, "key", 'materialization'::catalog_spec_type, "value"
	from jsonb_each(jsonb_extract_path(bundled_catalog_arg::jsonb, 'materializations'))
	on conflict (draft_id, catalog_name)
	do update set spec_type = excluded.spec_type, spec = excluded.spec;

	return;

end \$\$
language plpgsql;

commit;
EOF

