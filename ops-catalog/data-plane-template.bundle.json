{
  "collections": {
    "ops/rollups/L1/BASE_NAME/catalog-stats": {
      "schema": {"$defs":{"__flowInline1":{"$defs":{"docsAndBytes":{"properties":{"bytesTotal":{"default":0,"description":"Total number of bytes representing the JSON encoded documents","reduce":{"strategy":"sum"},"type":"integer"},"docsTotal":{"default":0,"description":"Total number of documents","reduce":{"strategy":"sum"},"type":"integer"}},"reduce":{"strategy":"merge"},"required":["docsTotal","bytesTotal"],"type":"object"},"transformStats":{"description":"Stats for a specific transform of a derivation, which will have an update, publish, or both.","properties":{"input":{"$ref":"#/$defs/docsAndBytes","description":"The input documents that were fed into this transform."},"source":{"description":"The name of the collection that this transform sources from","type":"string"}},"reduce":{"strategy":"merge"},"required":["input"],"type":"object"}},"$id":"file:///Users/phil/projects/flow/ops-catalog/stats.schema.yaml","$schema":"https://json-schema.org/draft-07/schema","description":"Statistics related to the processing of a Flow capture, derivation, or materialization","properties":{"capture":{"additionalProperties":{"properties":{"out":{"$ref":"#/$defs/docsAndBytes"},"right":{"$ref":"#/$defs/docsAndBytes","description":"Documents fed into the combiner from the source"}},"reduce":{"strategy":"merge"},"type":"object"},"description":"Capture stats, organized by collection. The keys of this object are the collection names, and the values are the stats for that collection.","reduce":{"strategy":"merge"},"type":"object"},"derive":{"properties":{"out":{"$ref":"#/$defs/docsAndBytes"},"published":{"$ref":"#/$defs/docsAndBytes"},"transforms":{"additionalProperties":{"$ref":"#/$defs/transformStats"},"description":"A map of each transform (transform name, not collection name) to stats for that transform","reduce":{"strategy":"merge"},"type":"object"}},"reduce":{"strategy":"merge"},"type":"object"},"interval":{"properties":{"uptimeSeconds":{"description":"Number of seconds that the task shard is metered as having been running","minimum":1,"reduce":{"strategy":"sum"},"type":"integer"},"usageRate":{"default":0,"description":"Usage rate which adjusts `uptimeSeconds` to determine the task's effective usage","minimum":0,"type":"number"}},"reduce":{"strategy":"merge"},"required":["uptimeSeconds"],"type":"object"},"materialize":{"additionalProperties":{"properties":{"left":{"$ref":"#/$defs/docsAndBytes"},"out":{"properties":{"bytesTotal":{"default":0,"description":"Total number of bytes representing the JSON encoded documents","reduce":{"strategy":"sum"},"type":"integer"},"docsTotal":{"default":0,"description":"Total number of documents","reduce":{"strategy":"sum"},"type":"integer"}},"reduce":{"strategy":"merge"},"required":["docsTotal"],"type":"object"},"right":{"$ref":"#/$defs/docsAndBytes"}},"reduce":{"strategy":"merge"},"type":"object"},"description":"A map of each binding source (collection name) to combiner stats for that binding","reduce":{"strategy":"merge"},"type":"object"},"openSecondsTotal":{"description":"Total time that the transaction was open before starting to commit","reduce":{"strategy":"sum"},"type":"number"},"shard":{"$ref":"shard.schema.yaml"},"ts":{"description":"Timestamp corresponding to the start of the transaction","format":"date-time","type":"string"},"txnCount":{"description":"Total number of transactions represented by this stats document","reduce":{"strategy":"sum"},"type":"integer"}},"reduce":{"strategy":"merge"},"required":["shard","ts"],"title":"Flow task stats","type":"object"},"__flowInline2":{"$id":"file:///Users/phil/projects/flow/ops-catalog/shard.schema.yaml","$schema":"https://json-schema.org/draft-07/schema","description":"Identifies a specific shard of a task, which may be the source of a log message or metrics","properties":{"build":{"description":"The id of the build that this shard was running at the time the log was written","pattern":"[0-9a-f]{16}","type":"string"},"keyBegin":{"description":"The inclusive beginning of the shard's assigned key range","pattern":"[0-9a-f]{8}","type":"string"},"kind":{"description":"The type of the catalog task","enum":["capture","derivation","materialization"]},"name":{"description":"The name of the catalog task (without the task type prefix)","type":"string"},"rClockBegin":{"description":"The inclusive beginning of the shard's assigned rClock range","pattern":"[0-9a-f]{8}","type":"string"}},"required":["kind","name","keyBegin","rClockBegin"],"title":"Flow shard id","type":"object"},"logCount":{"default":0,"description":"Total number of matching log events","reduce":{"strategy":"sum"},"type":"integer"}},"$id":"file:///Users/phil/projects/flow/ops-catalog/catalog-stats.schema.yaml","$schema":"https://json-schema.org/draft-07/schema","description":"Statistics related to the processing of a Flow catalog.","properties":{"catalogName":{"description":"Name of the Flow catalog","type":"string"},"grain":{"description":"Time grain that the stats are aggregated over","enum":["monthly","daily","hourly"]},"statsSummary":{"properties":{"errors":{"$ref":"#/$defs/logCount","description":"Total number of logged errors"},"failures":{"$ref":"#/$defs/logCount","description":"Total number of shard failures"},"readByMe":{"$ref":"stats.schema.yaml#/$defs/docsAndBytes"},"readFromMe":{"$ref":"stats.schema.yaml#/$defs/docsAndBytes"},"usageSeconds":{"default":0,"description":"Cumulative number of metered seconds of task usage","reduce":{"strategy":"sum"},"type":"integer"},"warnings":{"$ref":"#/$defs/logCount","description":"Total number of logged warnings"},"writtenByMe":{"$ref":"stats.schema.yaml#/$defs/docsAndBytes"},"writtenToMe":{"$ref":"stats.schema.yaml#/$defs/docsAndBytes"}},"reduce":{"strategy":"merge"},"type":"object"},"taskStats":{"properties":{"capture":{"$ref":"stats.schema.yaml#/properties/capture"},"derive":{"$ref":"stats.schema.yaml#/properties/derive"},"interval":{"$ref":"stats.schema.yaml#/properties/interval"},"materialize":{"$ref":"stats.schema.yaml#/properties/materialize"}},"reduce":{"strategy":"merge"},"type":"object"},"ts":{"description":"Timestamp of the catalog stat aggregate","format":"date-time","type":"string"}},"reduce":{"strategy":"merge"},"required":["catalogName","grain","ts","statsSummary"],"title":"Flow catalog task stats","type":"object"},
      "key": [
        "/catalogName",
        "/grain",
        "/ts"
      ],
      "derive": {
        "using": {
          "typescript": {
            "module": "import { Document, IDerivation, SourceLogs, SourceStats } from \"flow/ops/rollups/L1/BASE_NAME/catalog-stats.ts\";\n\n// Implementation for derivation ops/rollups/L1/BASE_NAME/catalog-stats.\nexport class Derivation extends IDerivation {\n    logs(read: { doc: SourceLogs }): Document[] {\n        const source = read.doc;\n        let stats: Document[\"statsSummary\"] = {};\n\n        if (source.level == \"error\" && source.message == \"shard failed\") {\n            stats = { failures: 1 };\n        } else if (source.level == \"error\") {\n            stats = { errors: 1 };\n        } else if (source.level == \"warn\") {\n            stats = { warnings: 1 };\n        } else {\n            return [];\n        }\n\n        const grains = grainsFromTS(new Date(source.ts));\n        return mapStatsToDocsByGrain(grains, { [source.shard.name]: stats });\n    }\n\n    stats(read: { doc: SourceStats }): Document[] {\n        const source = read.doc;\n        const ts = new Date(source.ts);\n        const grains = grainsFromTS(ts);\n\n        const taskDocs = mapStatsToDocsByGrain(grains, taskStats(source)).map((doc) => ({\n            ...doc,\n            // For documents generated specific to this task, retain the detailed information about\n            // the task itself.\n            taskStats: {\n                capture: source.capture,\n                derive: source.derive,\n                materialize: source.materialize,\n                interval: source.interval,\n            },\n        }));\n\n        // Documents generated for collections involved in this task will not have associated\n        // detailed task information. If the collection is a derivation, that will be accounted for\n        // above.\n        const collectionDocs = mapStatsToDocsByGrain(grains, collectionStats(source));\n\n        return [...taskDocs, ...collectionDocs];\n    }\n}\n\ntype TimeGrain = {\n    grain: Document[\"grain\"];\n    ts: string;\n};\n\nconst grainsFromTS = (ts: Date): TimeGrain[] => {\n    ts.setUTCMilliseconds(0);\n    ts.setUTCSeconds(0);\n    ts.setUTCMinutes(0);\n\n    const hourlyTS = ts.toISOString();\n    ts.setUTCHours(0);\n    const dailyTS = ts.toISOString();\n    ts.setUTCDate(1);\n    const monthlyTS = ts.toISOString();\n\n    return [\n        {\n            grain: \"hourly\" as Document[\"grain\"],\n            ts: hourlyTS,\n        },\n        {\n            grain: \"daily\" as Document[\"grain\"],\n            ts: dailyTS,\n        },\n        {\n            grain: \"monthly\" as Document[\"grain\"],\n            ts: monthlyTS,\n        },\n    ];\n};\n\ntype StatsData = {\n    [k: string]: Document[\"statsSummary\"];\n};\n\nconst mapStatsToDocsByGrain = (grains: TimeGrain[], stats: StatsData): Document[] =>\n    Object.entries(stats).flatMap(([catalogName, statsSummary]) =>\n        grains.map((g) => ({\n            ...g,\n            catalogName,\n            statsSummary,\n        }))\n    );\n\nconst taskStats = (source: SourceStats): StatsData => {\n    const stats: Document[\"statsSummary\"] = {};\n\n    // For captures, derivations, and materializations, we walk through all\n    // bound collections and sum up the total data written or read by this task.\n    if (source.capture) {\n        for (const collectionStats of Object.values(source.capture!)) {\n            stats.writtenByMe = accumulateStats(stats.writtenByMe, collectionStats.out);\n        }\n    } else if (source.materialize) {\n        for (const collectionStats of Object.values(source.materialize!)) {\n            stats.readByMe = accumulateStats(stats.readByMe, collectionStats.right);\n        }\n    } else if (source.derive) {\n        stats.writtenByMe = accumulateStats(stats.writtenByMe, source.derive!.out);\n        for (const transformStats of Object.values(source.derive!.transforms || {})) {\n            stats.readByMe = accumulateStats(stats.readByMe, transformStats.input);\n        }\n    } else if (source.interval?.usageRate) {\n        stats.usageSeconds = Math.round(source.interval.uptimeSeconds * source.interval.usageRate);\n    }\n\n    const output: StatsData = {};\n    output[source.shard.name] = stats;\n    return output;\n};\n\nconst collectionStats = (source: SourceStats): StatsData => {\n    const output: StatsData = {};\n\n    // An individual collection can be written to/read from a single time by a\n    // capture/materialization in a a single stats document, but as noted above there can be\n    // multiple collections bound by a task. So we will potentially emit multiple collection\n    // stats documents for a single task.\n    if (source.capture) {\n        for (const [collectionName, stats] of Object.entries(source.capture!)) {\n            if (!output[collectionName]) {\n                output[collectionName] = {};\n            }\n            output[collectionName].writtenToMe = accumulateStats(output[collectionName].writtenToMe, stats.out);\n        }\n    } else if (source.materialize) {\n        for (const [collectionName, stats] of Object.entries(source.materialize!)) {\n            if (!output[collectionName]) {\n                output[collectionName] = {};\n            }\n            output[collectionName].readFromMe = accumulateStats(output[collectionName].readFromMe, stats.right);\n        }\n    } else if (source.derive) {\n        // A derivation will have one collection written to (itself), and can read from multiple\n        // collections named in the transforms.\n\n        // The collection being written to is the name of the task.\n        if (!output[source.shard.name]) {\n            output[source.shard.name] = {};\n        }\n\n        output[source.shard.name].writtenToMe = accumulateStats(\n            output[source.shard.name].writtenToMe,\n            source.derive!.out,\n        );\n\n        // Each transform will include a source collection that is read from.\n        for (const transform of Object.values(source.derive!.transforms || {})) {\n            if (!transform.source) {\n                // Legacy stats docs may not list a source collection for derivations.\n                continue;\n            }\n\n            if (!output[transform.source]) {\n                output[transform.source] = {};\n            }\n\n            output[transform.source].readFromMe = accumulateStats(\n                output[transform.source].readFromMe,\n                transform.input,\n            );\n        }\n    }\n\n    return output;\n};\n\n// accumulateStats will reduce stats into the accumulator via addition with special handling to\n// return \"undefined\" rather than an explicit zero value if the stats are zero.\nconst accumulateStats = (\n    accumulator: { bytesTotal: number; docsTotal: number } | undefined,\n    stats: { bytesTotal: number; docsTotal: number } | undefined,\n): { bytesTotal: number; docsTotal: number } | undefined => {\n    // If there are no stats to add return the accumulator as-is.\n    if (!stats || (stats.bytesTotal === 0 && stats.docsTotal === 0)) {\n        return accumulator;\n    }\n\n    // There are stats to add, so make sure the accumulator is defined before adding them.\n    const returnedAccumulated = accumulator || { bytesTotal: 0, docsTotal: 0 };\n    returnedAccumulated.bytesTotal += stats.bytesTotal;\n    returnedAccumulated.docsTotal += stats.docsTotal;\n\n    return returnedAccumulated;\n};\n"
          }
        },
        "transforms": [
          {
            "name": "logs",
            "source": {
              "name": "ops/tasks/BASE_NAME/logs"
            },
            "shuffle": {
              "key": [
                "/shard/name"
              ]
            }
          },
          {
            "name": "stats",
            "source": {
              "name": "ops/tasks/BASE_NAME/stats"
            },
            "shuffle": {
              "key": [
                "/shard/name"
              ]
            }
          }
        ],
        "shards": {
          "minTxnDuration": "5s"
        }
      }
    },
    "ops/rollups/L1/BASE_NAME/events": {
      "schema": {"$defs":{"__flowInline1":{"$id":"file:///Users/phil/projects/flow/ops-catalog/logs.schema.yaml","$schema":"https://json-schema.org/draft-07/schema","description":"Logs related to the processing of a Flow capture, derivation, or materialization","properties":{"fields":{"additionalProperties":true,"description":"Map of keys and values that are associated with this log entry.","type":"object"},"level":{"enum":["error","warn","info","debug","trace"]},"message":{"type":"string"},"shard":{"$ref":"shard.schema.yaml"},"ts":{"description":"Timestamp corresponding to the start of the transaction","format":"date-time","type":"string"}},"required":["shard","ts","level"],"title":"Flow task logs","type":"object"},"__flowInline2":{"$id":"file:///Users/phil/projects/flow/ops-catalog/shard.schema.yaml","$schema":"https://json-schema.org/draft-07/schema","description":"Identifies a specific shard of a task, which may be the source of a log message or metrics","properties":{"build":{"description":"The id of the build that this shard was running at the time the log was written","pattern":"[0-9a-f]{16}","type":"string"},"keyBegin":{"description":"The inclusive beginning of the shard's assigned key range","pattern":"[0-9a-f]{8}","type":"string"},"kind":{"description":"The type of the catalog task","enum":["capture","derivation","materialization"]},"name":{"description":"The name of the catalog task (without the task type prefix)","type":"string"},"rClockBegin":{"description":"The inclusive beginning of the shard's assigned rClock range","pattern":"[0-9a-f]{8}","type":"string"}},"required":["kind","name","keyBegin","rClockBegin"],"title":"Flow shard id","type":"object"}},"$id":"file:///Users/phil/projects/flow/ops-catalog/events.schema.yaml","$ref":"logs.schema.yaml","$schema":"https://json-schema.org/draft-07/schema","description":"Events are special logs that are intended to be consumed by the control plane","properties":{"fields":{"additionalProperties":true,"properties":{"error":{"description":"If the event represents an error, this field contains the error message.\n","type":"string"},"eventTarget":{"description":"The target of the event is a catalog name that the event pertains to.\n","type":"string"},"eventType":{"description":"Identifies this log message as an event of the given type. Events\nare special logs that are meant to be observed by the Flow control plane.\n","type":"string"}},"required":["eventType","eventTarget"]},"shard":{"description":"The source of the event, which may differ from the eventTarget"}},"required":["fields"],"title":"Flow events"},
      "key": [
        "/fields/eventTarget",
        "/eventType"
      ],
      "projections": {
        "event_type": {
          "location": "/fields/eventType",
          "partition": true
        }
      },
      "derive": {
        "using": {
          "sqlite": {}
        },
        "transforms": [
          {
            "name": "logs",
            "source": "ops/tasks/BASE_NAME/logs",
            "shuffle": "any",
            "lambda": "select json($flow_document)\n  where json_type($fields, '$.eventType') = 'text'\n  and json_type($fields, '$.eventTarget') = 'text'\n  and json_type($fields, '$.error') in ('null', 'text');\n"
          }
        ],
        "shards": {
          "minTxnDuration": "5s"
        }
      }
    },
    "ops/rollups/L1/BASE_NAME/inferred-schemas": {
      "schema": {"$id":"file:///Users/phil/projects/flow/ops-catalog/inferred-schemas.schema.yaml","properties":{"collection_name":{"description":"The name of the collection that this schema was inferred for","type":"string"},"schema":{"description":"The inferred schema","reduce":{"strategy":"jsonSchemaMerge"},"type":"object"}},"reduce":{"strategy":"merge"},"required":["collection_name","schema"],"type":"object"},
      "key": [
        "/collection_name"
      ],
      "derive": {
        "using": {
          "sqlite": {}
        },
        "transforms": [
          {
            "name": "logs",
            "source": {
              "name": "ops/tasks/BASE_NAME/logs",
              "partitions": {
                "include": {
                  "kind": [
                    "capture",
                    "derivation"
                  ]
                },
                "exclude": {
                  "name": [
                    "ops/rollups/L1/BASE_NAME/inferred-schemas",
                    "ops.us-central1.v1/inferred-schemas/L2"
                  ]
                }
              }
            },
            "shuffle": {
              "key": [
                "/shard/name"
              ]
            },
            "lambda": "select\n  $fields->>'collection_name' as collection_name,\n  $fields->'schema' as schema\nwhere $message = 'inferred schema updated';\n"
          }
        ],
        "shards": {
          "minTxnDuration": "10s"
        }
      }
    },
    "ops/tasks/BASE_NAME/logs": {
      "schema": {"$defs":{"__flowInline1":{"$id":"file:///Users/phil/projects/flow/ops-catalog/shard.schema.yaml","$schema":"https://json-schema.org/draft-07/schema","description":"Identifies a specific shard of a task, which may be the source of a log message or metrics","properties":{"build":{"description":"The id of the build that this shard was running at the time the log was written","pattern":"[0-9a-f]{16}","type":"string"},"keyBegin":{"description":"The inclusive beginning of the shard's assigned key range","pattern":"[0-9a-f]{8}","type":"string"},"kind":{"description":"The type of the catalog task","enum":["capture","derivation","materialization"]},"name":{"description":"The name of the catalog task (without the task type prefix)","type":"string"},"rClockBegin":{"description":"The inclusive beginning of the shard's assigned rClock range","pattern":"[0-9a-f]{8}","type":"string"}},"required":["kind","name","keyBegin","rClockBegin"],"title":"Flow shard id","type":"object"}},"$id":"file:///Users/phil/projects/flow/ops-catalog/logs.schema.yaml","$schema":"https://json-schema.org/draft-07/schema","description":"Logs related to the processing of a Flow capture, derivation, or materialization","properties":{"fields":{"additionalProperties":true,"description":"Map of keys and values that are associated with this log entry.","type":"object"},"level":{"enum":["error","warn","info","debug","trace"]},"message":{"type":"string"},"shard":{"$ref":"shard.schema.yaml"},"ts":{"description":"Timestamp corresponding to the start of the transaction","format":"date-time","type":"string"}},"required":["shard","ts","level"],"title":"Flow task logs","type":"object"},
      "key": [
        "/shard/name",
        "/shard/keyBegin",
        "/shard/rClockBegin",
        "/ts"
      ],
      "projections": {
        "kind": {
          "location": "/shard/kind",
          "partition": true
        },
        "name": {
          "location": "/shard/name",
          "partition": true
        }
      }
    },
    "ops/tasks/BASE_NAME/stats": {
      "schema": {"$defs":{"__flowInline1":{"$id":"file:///Users/phil/projects/flow/ops-catalog/shard.schema.yaml","$schema":"https://json-schema.org/draft-07/schema","description":"Identifies a specific shard of a task, which may be the source of a log message or metrics","properties":{"build":{"description":"The id of the build that this shard was running at the time the log was written","pattern":"[0-9a-f]{16}","type":"string"},"keyBegin":{"description":"The inclusive beginning of the shard's assigned key range","pattern":"[0-9a-f]{8}","type":"string"},"kind":{"description":"The type of the catalog task","enum":["capture","derivation","materialization"]},"name":{"description":"The name of the catalog task (without the task type prefix)","type":"string"},"rClockBegin":{"description":"The inclusive beginning of the shard's assigned rClock range","pattern":"[0-9a-f]{8}","type":"string"}},"required":["kind","name","keyBegin","rClockBegin"],"title":"Flow shard id","type":"object"},"docsAndBytes":{"properties":{"bytesTotal":{"default":0,"description":"Total number of bytes representing the JSON encoded documents","reduce":{"strategy":"sum"},"type":"integer"},"docsTotal":{"default":0,"description":"Total number of documents","reduce":{"strategy":"sum"},"type":"integer"}},"reduce":{"strategy":"merge"},"required":["docsTotal","bytesTotal"],"type":"object"},"transformStats":{"description":"Stats for a specific transform of a derivation, which will have an update, publish, or both.","properties":{"input":{"$ref":"#/$defs/docsAndBytes","description":"The input documents that were fed into this transform."},"source":{"description":"The name of the collection that this transform sources from","type":"string"}},"reduce":{"strategy":"merge"},"required":["input"],"type":"object"}},"$id":"file:///Users/phil/projects/flow/ops-catalog/stats.schema.yaml","$schema":"https://json-schema.org/draft-07/schema","description":"Statistics related to the processing of a Flow capture, derivation, or materialization","properties":{"capture":{"additionalProperties":{"properties":{"out":{"$ref":"#/$defs/docsAndBytes"},"right":{"$ref":"#/$defs/docsAndBytes","description":"Documents fed into the combiner from the source"}},"reduce":{"strategy":"merge"},"type":"object"},"description":"Capture stats, organized by collection. The keys of this object are the collection names, and the values are the stats for that collection.","reduce":{"strategy":"merge"},"type":"object"},"derive":{"properties":{"out":{"$ref":"#/$defs/docsAndBytes"},"published":{"$ref":"#/$defs/docsAndBytes"},"transforms":{"additionalProperties":{"$ref":"#/$defs/transformStats"},"description":"A map of each transform (transform name, not collection name) to stats for that transform","reduce":{"strategy":"merge"},"type":"object"}},"reduce":{"strategy":"merge"},"type":"object"},"interval":{"properties":{"uptimeSeconds":{"description":"Number of seconds that the task shard is metered as having been running","minimum":1,"reduce":{"strategy":"sum"},"type":"integer"},"usageRate":{"default":0,"description":"Usage rate which adjusts `uptimeSeconds` to determine the task's effective usage","minimum":0,"type":"number"}},"reduce":{"strategy":"merge"},"required":["uptimeSeconds"],"type":"object"},"materialize":{"additionalProperties":{"properties":{"left":{"$ref":"#/$defs/docsAndBytes"},"out":{"properties":{"bytesTotal":{"default":0,"description":"Total number of bytes representing the JSON encoded documents","reduce":{"strategy":"sum"},"type":"integer"},"docsTotal":{"default":0,"description":"Total number of documents","reduce":{"strategy":"sum"},"type":"integer"}},"reduce":{"strategy":"merge"},"required":["docsTotal"],"type":"object"},"right":{"$ref":"#/$defs/docsAndBytes"}},"reduce":{"strategy":"merge"},"type":"object"},"description":"A map of each binding source (collection name) to combiner stats for that binding","reduce":{"strategy":"merge"},"type":"object"},"openSecondsTotal":{"description":"Total time that the transaction was open before starting to commit","reduce":{"strategy":"sum"},"type":"number"},"shard":{"$ref":"shard.schema.yaml"},"ts":{"description":"Timestamp corresponding to the start of the transaction","format":"date-time","type":"string"},"txnCount":{"description":"Total number of transactions represented by this stats document","reduce":{"strategy":"sum"},"type":"integer"}},"reduce":{"strategy":"merge"},"required":["shard","ts"],"title":"Flow task stats","type":"object"},
      "key": [
        "/shard/name",
        "/shard/keyBegin",
        "/shard/rClockBegin",
        "/ts"
      ],
      "projections": {
        "kind": {
          "location": "/shard/kind",
          "partition": true
        },
        "name": {
          "location": "/shard/name",
          "partition": true
        }
      }
    }
  }
}